{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5626793b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\requests\\__init__.py:109: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import必要套件\n",
    "from urllib import parse\n",
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from fake_useragent import UserAgent\n",
    "from time import time, sleep\n",
    "from random import randint\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32146bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "網站狀態碼: 200\n",
      "網站編碼　: UTF-8\n",
      "回覆標頭　: {'Date': 'Tue, 28 Jun 2022 14:30:28 GMT', 'Server': 'Apache', 'Set-Cookie': 'ks2=zd5qm9x5xn1; expires=Wed, 28-Jun-2023 14:30:28 GMT; Max-Age=31536000; path=/; domain=syosetu.com; secure', 'Content-Encoding': 'gzip', 'Vary': 'Accept-Encoding', 'Connection': 'close', 'Transfer-Encoding': 'chunked', 'Content-Type': 'text/html; charset=UTF-8'}\n"
     ]
    }
   ],
   "source": [
    "# 傳入URL、設定隨機UserAgent、發出請求並確認狀況\n",
    "url = 'https://ncode.syosetu.com/n9722do/'\n",
    "\n",
    "# 設定隨機UserAgent\n",
    "ua = UserAgent()\n",
    "my_headers = {\n",
    "    'User-Agent':ua.random\n",
    "}\n",
    "\n",
    "# 發出get request，確認連線狀況\n",
    "response = req.get(url, headers = my_headers)\n",
    "print(f'網站狀態碼: {response.status_code}')\n",
    "print(f'網站編碼　: {response.encoding}')\n",
    "print(f'回覆標頭　: {response.headers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d571b867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最強剣士、最底辺騎士団で奮戦中　～オークを地の果てまで追い詰めて絶対に始末するだけの簡単？なお仕事です～\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Python310\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 開始爬蟲 - 建立soup物件、取得小說名\n",
    "\n",
    "# 建立soup物件用lxml parser\n",
    "soup = bs(response.text, 'lxml')\n",
    "\n",
    "# 小說標題為只有一個內容的iterable物件，用index 0取出值\n",
    "novel_title = soup.select('div#novel_contents p.novel_title')[0].get_text()\n",
    "print(novel_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa1140",
   "metadata": {},
   "outputs": [],
   "source": [
    "novel_content = soup.select('div.index_box')\n",
    "\n",
    "for content in novel_content:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec1fa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 確認小說本體(div.index_box內部構造)\n",
    "novel_content = soup.select('div.index_box')\n",
    "\n",
    "regexChapterTitle = r'<div class=\\\"chapter_title\\\">([一-龯ぁ-んァ-ン　\\w]+)<\\/div>'\n",
    "# index_box內為一個巨大的content串列 (只有一個元素)\n",
    "# for element in novel_content:\n",
    "#     print(f\"=====\\n{element}\\n=====\")\n",
    "\n",
    "# print(novel_content)\n",
    "print(re.search(regexChapterTitle, str(novel_content))[1])\n",
    "\n",
    "print(f\"novel_content元素類型: {type(novel_content)}\")\n",
    "print(f\"novel_content內元素數: {len(novel_content)}\")\n",
    "print(f\"novel_content內文: \\n{novel_content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c5364d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item: <div class=\"chapter_title\">第一章　そろそろ入団3年目</div>\n",
      "==================================================\n",
      "item: <dl class=\"novel_sublist2\">\n",
      "<dd class=\"subtitle\">\n",
      "<a href=\"/n9722do/1/\">1.物語の始まりです</a>\n",
      "</dd>\n",
      "<dt class=\"long_update\">\n",
      "2016/10/16 22:00<span title=\"2020/11/23 01:30 改稿\">（<u>改</u>）</span></dt>\n",
      "</dl>\n",
      "==================================================\n",
      "item: <dl class=\"novel_sublist2\">\n",
      "<dd class=\"subtitle\">\n",
      "<a href=\"/n9722do/2/\">2.殺せばいい訳ではありません</a>\n",
      "</dd>\n",
      "<dt class=\"long_update\">\n",
      "2016/11/25 02:42<span title=\"2020/01/31 15:15 改稿\">（<u>改</u>）</span></dt>\n",
      "</dl>\n",
      "==================================================\n",
      "\n",
      "\n",
      "===== 分隔線 =====\n",
      "\n",
      "\n",
      "item: <div class=\"chapter_title\">第一章　そろそろ入団3年目</div>\n",
      "==================================================\n",
      "item: <dl class=\"novel_sublist2\">\n",
      "<dd class=\"subtitle\">\n",
      "<a href=\"/n9722do/1/\">1.物語の始まりです</a>\n",
      "</dd>\n",
      "<dt class=\"long_update\">\n",
      "2016/10/16 22:00<span title=\"2020/11/23 01:30 改稿\">（<u>改</u>）</span></dt>\n",
      "</dl>\n",
      "==================================================\n",
      "item: <dl class=\"novel_sublist2\">\n",
      "<dd class=\"subtitle\">\n",
      "<a href=\"/n9722do/2/\">2.殺せばいい訳ではありません</a>\n",
      "</dd>\n",
      "<dt class=\"long_update\">\n",
      "2016/11/25 02:42<span title=\"2020/01/31 15:15 改稿\">（<u>改</u>）</span></dt>\n",
      "</dl>\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# div.index_box內第一個層級有div以及dl 2種元素標籤，設定讓select 2種都算\n",
    "novel_content = soup.select('div.index_box')\n",
    "content = novel_content[0].select('div, dl')\n",
    "\n",
    "for item in content[0:3]:\n",
    "    print(f\"item: {item}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "print(\"\\n\\n===== 分隔線 =====\\n\\n\")\n",
    "\n",
    "novel_content2 = soup.select('div.index_box div,dl')\n",
    "for item in novel_content2[0:3]:\n",
    "    print(f\"item: {item}\")\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01908027-1f5d-4118-82a8-918ec9cc7be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "章名:第一章　そろそろ入団3年目　節名:1.物語の始まりです　上傳時間:2016/10/16 22:00　更新時間:2020/11/23 01:30　連結:https://ncode.syosetu.com/n9722do/1/\n",
      "章名:第一章　そろそろ入団3年目　節名:2.殺せばいい訳ではありません　上傳時間:2016/11/25 02:42　更新時間:2020/01/31 15:15　連結:https://ncode.syosetu.com/n9722do/2/\n",
      "章名:第一章　そろそろ入団3年目　節名:3.鎧なんて飾りです　上傳時間:2016/10/18 22:00　更新時間:2020/01/31 15:15　連結:https://ncode.syosetu.com/n9722do/3/\n",
      "章名:第一章　そろそろ入団3年目　節名:4.苦労の割に安月給です　上傳時間:2016/10/20 17:00　更新時間:2020/01/31 15:15　連結:https://ncode.syosetu.com/n9722do/4/\n",
      "章名:第一章　そろそろ入団3年目　節名:5.魔法で敵は倒せません　上傳時間:2016/10/22 15:00　更新時間:2020/01/31 15:16　連結:https://ncode.syosetu.com/n9722do/5/\n",
      "章名:第一章　そろそろ入団3年目　節名:6.責任はやたらと重大です　上傳時間:2016/10/24 15:00　更新時間:2021/04/24 20:30　連結:https://ncode.syosetu.com/n9722do/6/\n",
      "章名:第二章　王都で御前試合　節名:7.人参は経費で落ちません　上傳時間:2016/10/26 15:00　更新時間:2020/01/31 15:17　連結:https://ncode.syosetu.com/n9722do/7/\n",
      "章名:第二章　王都で御前試合　節名:8.絆は時として残酷です　上傳時間:2016/10/28 15:00　更新時間:2020/09/14 21:13　連結:https://ncode.syosetu.com/n9722do/8/\n",
      "章名:第二章　王都で御前試合　節名:9.無駄な知識は豊富です　上傳時間:2016/10/30 16:00　更新時間:2020/01/31 15:18　連結:https://ncode.syosetu.com/n9722do/9/\n",
      "章名:第二章　王都で御前試合　節名:10.たまには本気で戦います　上傳時間:2016/11/01 15:00　更新時間:2020/01/29 23:56　連結:https://ncode.syosetu.com/n9722do/10/\n",
      "章名:第二章　王都で御前試合　節名:11.恥の形は様々です　上傳時間:2016/11/03 16:00　更新時間:2022/02/12 03:01　連結:https://ncode.syosetu.com/n9722do/11/\n",
      "章名:第二章　王都で御前試合　節名:12.正しい奥義が分かりません　上傳時間:2016/11/06 08:00　更新時間:2020/01/31 15:19　連結:https://ncode.syosetu.com/n9722do/12/\n",
      "章名:第二章　王都で御前試合　節名:13.人間は知恵で戦います　上傳時間:2016/11/15 08:00　更新時間:2021/12/14 18:46　連結:https://ncode.syosetu.com/n9722do/13/\n",
      "章名:第三章　課題山積の山　節名:14.新人の朝は早いです　上傳時間:2016/11/19 08:00　更新時間:2022/02/12 02:57　連結:https://ncode.syosetu.com/n9722do/14/\n",
      "章名:第三章　課題山積の山　節名:15.作戦はある意味失敗です　上傳時間:2016/11/24 08:00　更新時間:2021/10/28 16:08　連結:https://ncode.syosetu.com/n9722do/15/\n",
      "章名:第三章　課題山積の山　節名:16.新しすぎて分かりません　上傳時間:2016/12/03 08:00　更新時間:2020/01/31 15:20　連結:https://ncode.syosetu.com/n9722do/16/\n",
      "章名:第三章　課題山積の山　節名:17.ここが皆の戦場です　上傳時間:2016/12/09 08:00　更新時間:2020/04/08 02:33　連結:https://ncode.syosetu.com/n9722do/17/\n"
     ]
    }
   ],
   "source": [
    "novel_content = soup.select('div.index_box div,dl')\n",
    "chapterInfo = []\n",
    "regexDateTime = r'([\\d]{4}/[\\d]+/[\\d]+) ([\\d]{2}:[\\d]{2})'\n",
    "\n",
    "# for item in novel_content:\n",
    "#     print(item)\n",
    "#     print(\"=\" * 50)\n",
    "\n",
    "section = ''\n",
    "for item in novel_content[0:20]:\n",
    "    if item['class']==['chapter_title']:\n",
    "        section = item.get_text()\n",
    "        continue\n",
    "    else:\n",
    "        chapterTitle = item.a.get_text()\n",
    "        uploadDateTime = re.search(regexDateTime, item.dt.get_text())[0]\n",
    "        updateDateTime = ''\n",
    "        if item.find('span') != None:\n",
    "            updateDateTime = re.search(regexDateTime, item.span['title'])[0]\n",
    "        chapterLink = f\"https://ncode.syosetu.com{item.a['href']}\"\n",
    "\n",
    "    link = [section, chapterTitle, uploadDateTime, updateDateTime, chapterLink]\n",
    "    chapterInfo.append(link)\n",
    "\n",
    "# 確認抓到資料(for-each)\n",
    "for item in chapterInfo:\n",
    "    print(f\"章名:{item[0]}　節名:{item[1]}　上傳時間:{item[2]}　更新時間:{item[3]}　連結:{item[4]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "967db13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "章名:第一章　そろそろ入団3年目　節名:1.物語の始まりです　上傳時間:2016/10/16 22:00　更新時間:2020/11/23 01:30　連結:https://ncode.syosetu.com/n9722do/1/\n",
      "章名:第一章　そろそろ入団3年目　節名:2.殺せばいい訳ではありません　上傳時間:2016/11/25 02:42　更新時間:2020/01/31 15:15　連結:https://ncode.syosetu.com/n9722do/2/\n",
      "章名:第一章　そろそろ入団3年目　節名:3.鎧なんて飾りです　上傳時間:2016/10/18 22:00　更新時間:2020/01/31 15:15　連結:https://ncode.syosetu.com/n9722do/3/\n",
      "章名:第一章　そろそろ入団3年目　節名:4.苦労の割に安月給です　上傳時間:2016/10/20 17:00　更新時間:2020/01/31 15:15　連結:https://ncode.syosetu.com/n9722do/4/\n",
      "章名:第一章　そろそろ入団3年目　節名:5.魔法で敵は倒せません　上傳時間:2016/10/22 15:00　更新時間:2020/01/31 15:16　連結:https://ncode.syosetu.com/n9722do/5/\n",
      "章名:第一章　そろそろ入団3年目　節名:6.責任はやたらと重大です　上傳時間:2016/10/24 15:00　更新時間:2021/04/24 20:30　連結:https://ncode.syosetu.com/n9722do/6/\n",
      "章名:第二章　王都で御前試合　節名:7.人参は経費で落ちません　上傳時間:2016/10/26 15:00　更新時間:2020/01/31 15:17　連結:https://ncode.syosetu.com/n9722do/7/\n",
      "章名:第二章　王都で御前試合　節名:8.絆は時として残酷です　上傳時間:2016/10/28 15:00　更新時間:2020/09/14 21:13　連結:https://ncode.syosetu.com/n9722do/8/\n",
      "章名:第二章　王都で御前試合　節名:9.無駄な知識は豊富です　上傳時間:2016/10/30 16:00　更新時間:2020/01/31 15:18　連結:https://ncode.syosetu.com/n9722do/9/\n",
      "章名:第二章　王都で御前試合　節名:10.たまには本気で戦います　上傳時間:2016/11/01 15:00　更新時間:2020/01/29 23:56　連結:https://ncode.syosetu.com/n9722do/10/\n",
      "章名:第二章　王都で御前試合　節名:11.恥の形は様々です　上傳時間:2016/11/03 16:00　更新時間:2022/02/12 03:01　連結:https://ncode.syosetu.com/n9722do/11/\n",
      "章名:第二章　王都で御前試合　節名:12.正しい奥義が分かりません　上傳時間:2016/11/06 08:00　更新時間:2020/01/31 15:19　連結:https://ncode.syosetu.com/n9722do/12/\n",
      "章名:第二章　王都で御前試合　節名:13.人間は知恵で戦います　上傳時間:2016/11/15 08:00　更新時間:2021/12/14 18:46　連結:https://ncode.syosetu.com/n9722do/13/\n",
      "章名:第三章　課題山積の山　節名:14.新人の朝は早いです　上傳時間:2016/11/19 08:00　更新時間:2022/02/12 02:57　連結:https://ncode.syosetu.com/n9722do/14/\n",
      "章名:第三章　課題山積の山　節名:15.作戦はある意味失敗です　上傳時間:2016/11/24 08:00　更新時間:2021/10/28 16:08　連結:https://ncode.syosetu.com/n9722do/15/\n",
      "章名:第三章　課題山積の山　節名:16.新しすぎて分かりません　上傳時間:2016/12/03 08:00　更新時間:2020/01/31 15:20　連結:https://ncode.syosetu.com/n9722do/16/\n",
      "章名:第三章　課題山積の山　節名:17.ここが皆の戦場です　上傳時間:2016/12/09 08:00　更新時間:2020/04/08 02:33　連結:https://ncode.syosetu.com/n9722do/17/\n",
      "章名:第三章　課題山積の山　節名:18.誰かの為に強くなります　上傳時間:2016/12/14 08:00　更新時間:2020/01/31 15:22　連結:https://ncode.syosetu.com/n9722do/18/\n",
      "章名:第三章　課題山積の山　節名:19.表は白くても裏は真っ黒です　上傳時間:2016/12/19 08:00　更新時間:2020/01/31 15:21　連結:https://ncode.syosetu.com/n9722do/19/\n",
      "章名:第四章　荒地と断崖の町　節名:20.必ずしも蔑称ではありません　上傳時間:2016/12/24 08:00　更新時間:2020/01/29 23:56　連結:https://ncode.syosetu.com/n9722do/20/\n"
     ]
    }
   ],
   "source": [
    "# 抓出章名以及其中小說節名\n",
    "novel_content = soup.select('div.index_box')\n",
    "regexChapterTitle = r'<div class=\\\"chapter_title\\\">([一-龯ぁ-んァ-ン　\\w]+)<\\/div>'\n",
    "chapterInfoSource = soup.select('div.index_box dl.novel_sublist2')\n",
    "chapterInfo = []\n",
    "regexDateTime = r'([\\d]{4}/[\\d]+/[\\d]+) ([\\d]{2}:[\\d]{2})'\n",
    "howMany = 20\n",
    "\n",
    "# 不限制取出筆數\n",
    "# for item in chapterInfoSource:\n",
    "#     sectionSliceIndex = str(novel_content).find(item.a.get_text())\n",
    "#     sectionString = str(novel_content)[0:sectionSliceIndex]\n",
    "#     section = re.findall(regexChapterTitle, sectionString)\n",
    "#     latest_section = section[len(section)-1]\n",
    "#     chapterTitle = item.a.get_text()\n",
    "#     uploadDateTime = re.search(regexDateTime, item.dt.get_text())[0]\n",
    "#     updateDateTime = ''\n",
    "#     if item.find('span') != None:\n",
    "#         updateDateTime = re.search(regexDateTime, item.span['title'])[0]\n",
    "#     chapterLink = f\"https://ncode.syosetu.com{item.a['href']}\"\n",
    "\n",
    "#     link = [latest_section, chapterTitle, uploadDateTime, updateDateTime, chapterLink]\n",
    "#     chapterInfo.append(link)\n",
    "\n",
    "\n",
    "# 限制取出筆數\n",
    "for i in range(howMany):\n",
    "    sectionSliceIndex = str(novel_content).find(chapterInfoSource[i].a.get_text())\n",
    "    sectionString = str(novel_content)[0:sectionSliceIndex]\n",
    "    section = re.findall(regexChapterTitle, sectionString)\n",
    "    latest_section = section[len(section)-1]\n",
    "    chapterTitle = chapterInfoSource[i].a.get_text()\n",
    "    uploadDateTime = re.search(regexDateTime, chapterInfoSource[i].dt.get_text())[0]\n",
    "    updateDateTime = ''\n",
    "    if chapterInfoSource[i].find('span') != None:\n",
    "        updateDateTime = re.search(regexDateTime, chapterInfoSource[i].span['title'])[0]\n",
    "    chapterLink = f\"https://ncode.syosetu.com{chapterInfoSource[i].a['href']}\"\n",
    "\n",
    "\n",
    "    link = [latest_section, chapterTitle, uploadDateTime, updateDateTime, chapterLink]\n",
    "    chapterInfo.append(link)\n",
    "\n",
    "    \n",
    "# 確認抓到資料        \n",
    "# i = 0\n",
    "# for i in range(50):\n",
    "#     print(f\"{i+1}. {chapterInfo[i]}\")\n",
    "\n",
    "\n",
    "# 確認抓到資料(for-each)\n",
    "for item in chapterInfo:\n",
    "    print(f\"章名:{item[0]}　節名:{item[1]}　上傳時間:{item[2]}　更新時間:{item[3]}　連結:{item[4]}\")\n",
    "\n",
    "\n",
    "\n",
    "# 一筆一筆抓出每個\n",
    "# for title in chapter_titles:\n",
    "#     sectionSliceIndex = str(novel_content).find(title.a.get_text())\n",
    "#     sectionString = str(novel_content)[0:sectionSliceIndex]\n",
    "#     section = re.findall(regexChapterTitle, sectionString)\n",
    "#     latest_section = section[len(section)-1]\n",
    "#     print(f\"{latest_section}　　{title.a.get_text()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc6ff886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一章　そろそろ入団3年目1.物語の始まりです2016/10/16 22:002020/11/23 01:30https://ncode.syosetu.com/n9722do/1/\n",
      "==================================================\n",
      "第一章　そろそろ入団3年目2.殺せばいい訳ではありません2016/11/25 02:422020/01/31 15:15https://ncode.syosetu.com/n9722do/2/\n",
      "==================================================\n",
      "第一章　そろそろ入団3年目3.鎧なんて飾りです2016/10/18 22:002020/01/31 15:15https://ncode.syosetu.com/n9722do/3/\n",
      "==================================================\n",
      "第一章　そろそろ入団3年目4.苦労の割に安月給です2016/10/20 17:002020/01/31 15:15https://ncode.syosetu.com/n9722do/4/\n",
      "==================================================\n",
      "第一章　そろそろ入団3年目5.魔法で敵は倒せません2016/10/22 15:002020/01/31 15:16https://ncode.syosetu.com/n9722do/5/\n",
      "==================================================\n",
      "第一章　そろそろ入団3年目6.責任はやたらと重大です2016/10/24 15:002021/04/24 20:30https://ncode.syosetu.com/n9722do/6/\n",
      "==================================================\n",
      "第二章　王都で御前試合7.人参は経費で落ちません2016/10/26 15:002020/01/31 15:17https://ncode.syosetu.com/n9722do/7/\n",
      "==================================================\n",
      "第二章　王都で御前試合8.絆は時として残酷です2016/10/28 15:002020/09/14 21:13https://ncode.syosetu.com/n9722do/8/\n",
      "==================================================\n",
      "第二章　王都で御前試合9.無駄な知識は豊富です2016/10/30 16:002020/01/31 15:18https://ncode.syosetu.com/n9722do/9/\n",
      "==================================================\n",
      "第二章　王都で御前試合10.たまには本気で戦います2016/11/01 15:002020/01/29 23:56https://ncode.syosetu.com/n9722do/10/\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 抓出章名以及其中小說節名\n",
    "novel_content = soup.select('div.index_box')\n",
    "regexChapterTitle = r'<div class=\\\"chapter_title\\\">([一-龯ぁ-んァ-ン　\\w]+)<\\/div>'\n",
    "chapterInfoSource = soup.select('div.index_box dl.novel_sublist2')\n",
    "chapterInfoDict = {'latest_section':[], 'chapterTitle':[], 'uploadDateTime':[], 'updateDateTime':[], 'chapterLink':[]}\n",
    "regexDateTime = r'([\\d]{4}/[\\d]+/[\\d]+) ([\\d]{2}:[\\d]{2})'\n",
    "\n",
    "\n",
    "\n",
    "# 限制取出筆數\n",
    "for i in range(10):\n",
    "    sectionSliceIndex = str(novel_content).find(chapterInfoSource[i].a.get_text())\n",
    "    sectionString = str(novel_content)[0:sectionSliceIndex]\n",
    "    section = re.findall(regexChapterTitle, sectionString)\n",
    "    latest_section = section[len(section)-1]\n",
    "    chapterTitle = chapterInfoSource[i].a.get_text()\n",
    "    uploadDateTime = re.search(regexDateTime, chapterInfoSource[i].dt.get_text())[0]\n",
    "    updateDateTime = ''\n",
    "    if chapterInfoSource[i].find('span') != None:\n",
    "        updateDateTime = re.search(regexDateTime, chapterInfoSource[i].span['title'])[0]\n",
    "    chapterLink = f\"https://ncode.syosetu.com{chapterInfoSource[i].a['href']}\"\n",
    "\n",
    "    chapterInfoDict['latest_section'].append(latest_section)\n",
    "    chapterInfoDict['chapterTitle'].append(chapterTitle)\n",
    "    chapterInfoDict['uploadDateTime'].append(uploadDateTime)\n",
    "    chapterInfoDict['updateDateTime'].append(updateDateTime)\n",
    "    chapterInfoDict['chapterLink'].append(chapterLink)\n",
    "    \n",
    "# print(chapterInfoDict)\n",
    "\n",
    "for i in range(10):\n",
    "    print(chapterInfoDict['latest_section'][i], end='')\n",
    "    print(chapterInfoDict['chapterTitle'][i], end='')\n",
    "    print(chapterInfoDict['uploadDateTime'][i], end='')\n",
    "    print(chapterInfoDict['updateDateTime'][i], end='')\n",
    "    print(chapterInfoDict['chapterLink'][i])\n",
    "    print(\"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08595173",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68dbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立章節資料夾\n",
    "# illegal_c = 不能出現在資料夾名判定用字串\n",
    "\n",
    "illegal_c = '[@_!#$%^&*()<>?/|}{~:]'\n",
    "\n",
    "\n",
    "for item in chapterInfo:\n",
    "    \n",
    "    # ===== 建立章資料夾 =====\n",
    "    chapterPath = ''\n",
    "    for char in item[0]:\n",
    "        if char in illegal_c:\n",
    "            truncateIndex = item[0].find(char)\n",
    "            chapterPath = f\"{folderPath}/{item[0][0:truncateIndex]}\"\n",
    "            break\n",
    "        else:\n",
    "            chapterPath = f\"{folderPath}/{item[0]}\"\n",
    "\n",
    "    if not os.path.exists(chapterPath):\n",
    "        os.makedirs(chapterPath)\n",
    "    # ===== 區塊結束 =====\n",
    "    \n",
    "    # ===== 建立爬文章本文需要的呼叫、soup物件，以及檔名 =====\n",
    "    res_chapter = req.get(link[4], headers = my_headers)\n",
    "    soup_chapter = bs(res_chapter.text, 'lxml')\n",
    "    chapter_content = soup_chapter.select('div#novel_honbun p')\n",
    "    chapter_title = item[1]\n",
    "    \n",
    "    for char in chapter_title:\n",
    "        if char in illegal_c:\n",
    "            chapter_title = chapter_title.replace(char, '')\n",
    "    # ===== 區塊結束 =====\n",
    "    \n",
    "    # ===== 開啟檔案並寫入 =====\n",
    "    with open(f'{chapterPath}/{chapter_title}.txt', 'w', encoding='utf-8') as novel_file:\n",
    "        novel_file.write(f\"タイトル：{item[1]}\\n更新日時：{item[2]}\\n最終更新：{item[3]}\\n\\n\\n\")\n",
    "        for text in chapter_content:\n",
    "            novel_file.write(f\"{text.get_text()}\\n\")\n",
    "\n",
    "    # 爬連結間空3~7秒避免因太過頻繁被認定是爬蟲\n",
    "    sleep(randint(3, 7))\n",
    "    # ===== 區塊結束 =====\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得、印出各小說章節連結list\n",
    "chapter_link = []\n",
    "for link in soup.select('div.index_box dd.subtitle a'):\n",
    "    chapter_link.append(f\"https://ncode.syosetu.com{link['href']}\")\n",
    "    \n",
    "for link in chapter_link:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a5a1c-fa49-4e71-9e1a-0ee25b665d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得各小說章節連結 - 追加章節名、上傳時間、更新時間，存入串列的串列格式\n",
    "# print(soup.select('div.index_box dl.novel_sublist2')[0])\n",
    "\n",
    "# # 測試output用\n",
    "# print(soup.select('div.index_box dl.novel_sublist2')[0].a.get_text())\n",
    "# print(soup.select('div.index_box dl.novel_sublist2')[0].a['href'])\n",
    "# print(soup.select('div.index_box dl.novel_sublist2')[0].dt.get_text())\n",
    "# print(soup.select('div.index_box dl.novel_sublist2')[0].dt.span['title'])\n",
    "\n",
    "chapterInfoSource = soup.select('div.index_box dl.novel_sublist2')\n",
    "regexDateTime = r'([\\d]{4}/[\\d]+/[\\d]+) ([\\d]{2}:[\\d]{2})'\n",
    "\n",
    "chapterInfo = []\n",
    "for item in chapterInfoSource:\n",
    "    chapterTitle = item.a.get_text()\n",
    "    uploadedTime = re.search(regexDateTime, item.dt.get_text())\n",
    "    # uploadedTime = item.dt.get_text()\n",
    "    updateTime = ''\n",
    "    if item.find('span') != None:\n",
    "        updateTime = re.search(regexDateTime, item.span['title'])[2]\n",
    "        # updateTime = item.span['title']\n",
    "    chapterLink = f\"https://ncode.syosetu.com{item.a['href']}\"\n",
    "        \n",
    "    link = [chapterTitle, uploadedTime, updateTime, chapterTitle]\n",
    "            \n",
    "    chapterInfo.append(link)\n",
    "\n",
    "i = 0\n",
    "for i in range(len(chapterInfo)):\n",
    "    print(f\"{i+1}. {chapterInfo}\")\n",
    "\n",
    "# # repr()確認是否含特殊符號\n",
    "# print(repr(soup.select('div.index_box dl.novel_sublist2')[0].a.get_text()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea63e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 印出小說標題、小說章節標題以及連結\n",
    "# 小說標題\n",
    "\n",
    "print(novel_title, end='\\n\\n')\n",
    "\n",
    "# while迴圈加入印出數量限制作法\n",
    "chapter_title = soup.select('div.index_box dd.subtitle a')\n",
    "i=0\n",
    "while i < 50:\n",
    "    print(chapter_title[i].get_text(), end='')\n",
    "    print(f\" https://ncode.syosetu.com{chapter_title[i]['href']}\")\n",
    "    print('=' * 20)\n",
    "    i+=1\n",
    "\n",
    "\n",
    "# # for 迴圈印出全部章節標題+連結做法\n",
    "# for chapter_title in soup.select('div.index_box dd.subtitle a'):\n",
    "#     print(chapter_title.get_text(), end='')\n",
    "#     print(f\" https://ncode.syosetu.com{chapter_title['href']}\")\n",
    "#     print('=' * 20)\n",
    "\n",
    "# # 印出小說連結一覽\n",
    "i = 0\n",
    "for i in range(50):\n",
    "    print(f\"{i+1}. {chapter_link[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc039a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓出各個章節的詳細資訊\n",
    "\n",
    "# 從上到下依序為章節資訊、章節標題、首次上傳時間、更新時間、連結 (抓出第一筆測試)\n",
    "chapter_info = soup.select('div.index_box dl.novel_sublist2')\n",
    "chapter_title = chapter_info[0].a.get_text()\n",
    "upload_date = chapter_info[0].dt.get_text()\n",
    "update_date = chapter_info[0].dt.span['title']\n",
    "novel_link = chapter_info[0].a['href']\n",
    "\n",
    "# # print(chapter_info)\n",
    "# print(chapter_title)\n",
    "# print(upload_date)\n",
    "# print(update_date)\n",
    "# print(novel_link)\n",
    "\n",
    "# 正規表達式 - 從抓到的資料中只抓出日期，另把日期以及時間個別群組化方便用index取用\n",
    "regex_date = r'([\\d]{4}/[\\d]+/[\\d]+) ([\\d]{2}:[\\d]{2})'\n",
    "\n",
    "# 印出章節名、上傳日、更新日(如果有)\n",
    "for info in chapter_info:\n",
    "    print(info.a.get_text())\n",
    "    print(f\"アップ日:{re.search(regex_date, info.dt.get_text())[1]}\", end='　')\n",
    "    if info.find('span') != None:\n",
    "        print(f\"改稿日:{re.search(regex_date, info.span['title'])[1]}\")\n",
    "    print(f\" https://ncode.syosetu.com{info.a['href']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68106a-b1e7-4789-954b-b329b1b925da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取上傳時間、更新時間(更新時間為null時不印)\n",
    "for info in chapter_info:\n",
    "    print(info.dt.get_text(), end='')\n",
    "    if info.find('span') != None:\n",
    "        print(info.dt.span['title'])\n",
    "        \n",
    "# for info in soup.select('div.index_box dl.novel_sublist2'):\n",
    "#     print(info.dt['long_update'].span['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a48916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取小說章節標題\n",
    "section_title = soup.select('div.chapter_title')\n",
    "\n",
    "for section in section_title:\n",
    "    print(section.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852af84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 建立存放小說的資料夾\n",
    "# folderPath = novel_title.split('　')[0] # 小說的名字、去除空格後的多餘字元\n",
    "# if not os.path.exists(folderPath):\n",
    "#     os.makedirs(folderPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd42d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從chapter_link從中抓出一篇小說\n",
    "\n",
    "# 呼叫chapter_link第一個連結，傳出請求、建立soup物件\n",
    "res_chapter = req.get(chapter_link[0], headers = my_headers)\n",
    "soup_chapter = bs(res_chapter.text, 'lxml')\n",
    "\n",
    "# 取出連結內章節的標題\n",
    "chapter_title = soup_chapter.select('p.novel_subtitle')[0].get_text()\n",
    "print(chapter_title, end='\\n')\n",
    "\n",
    "# 無法用於或不建議用於檔案名的非法字元\n",
    "illegal_c = '[@_!#$%^&*()<>?/|}{~:]　'\n",
    "\n",
    "# 若檔名包含非法字元，用replace移除\n",
    "for char in chapter_title:\n",
    "    if char in illegal_c:\n",
    "        chapter_title = chapter_title.replace(char, '')\n",
    "\n",
    "# 取出連結內章節的內文\n",
    "chapter_content = soup_chapter.select('div#novel_honbun p')\n",
    "for text in chapter_content:\n",
    "    print(text.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608fa9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 把小說的文字存入檔案，加入換行字元改善可讀性\n",
    "# with open(f'{folderPath}/{chapter_title}.txt', 'w', encoding='utf-8') as novel_file:\n",
    "#     novel_file.write(f\"{chapter_title}\\n\\n\")\n",
    "#     for text in chapter_content:\n",
    "#         novel_file.write(f\"{text.get_text()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899576f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把小說標題切到其中不合法字元前一個index，作為儲存檔案資料夾的名字\n",
    "\n",
    "illegal_c = '[@_!#$%^&*()<>?/|}{~:]　'\n",
    "folderPath = ''\n",
    "\n",
    "for char in novel_title:\n",
    "    if char in illegal_c:\n",
    "        truncateIndex = novel_title.find(char)\n",
    "        folderPath = novel_title[0:truncateIndex]\n",
    "        break\n",
    "print(folderPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a0b72",
   "metadata": {},
   "source": [
    "### 程式碼改善目標\n",
    "1. 使可以判讀是否已有已抓到的章節，有時則跳過該章節\n",
    "2. 設定能智慧截短小說標題避免觸發windows路徑長度限制 (在最短、合理的地方截斷標題)\n",
    "3. 抓到小說更新時間放在小說內\n",
    "4. 為各個章節建立子資料夾、加上編號\n",
    "\n",
    "全角日文字比對用Regex：https://bas-man.dev/post/python/regex-double-byte-python3/\n",
    "\n",
    "比對不在ASCII編碼中的字元：https://stackoverflow.com/questions/150033/regular-expression-to-match-non-ascii-characters\n",
    "\n",
    "參考 - 找文字方法：https://www.delftstack.com/howto/python/position-of-character-in-string/\n",
    "\n",
    "在bs物件內找有沒有子標籤：https://stackoverflow.com/questions/33238091/test-if-children-tag-exists-in-beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd02920d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
