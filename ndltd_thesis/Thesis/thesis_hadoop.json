[
    {
        "resulNum": "1.",
        "title": "實現支援QoS優先權機制之Hadoop雲端系統",
        "link": "https://hdl.handle.net/11296/zpf49x",
        "description": "近年來雲端系統為普遍大眾所使用，Hadoop 是一個成熟的雲端平台，開放原始碼受到廣泛應用以及具有高延展性的雲端作業系統，Hadoop 針對執行中的應用程式有提供資源分配的方式，而優先權是個重要的議題。因此在忙碌的系統中，總會遇到需要盡快完成的工作，希望系統能幫我們盡快完成，減少等待資源的時間。本研究透過修改 Hadoop 資源管理系統的預設排程器 FairScheduler 來實現Hadoop 中 Quality of Service (QoS) 的優先權機制，實驗中模擬了 Hadoop 系統中在不同佇列裡設定不同資源比例的同時，執行多個應用程式，相較於一般執行環境,當程式以具優先權的情況下執行，我們的設計能最高能減少其 39.84% 的執行時間。關鍵字: Hadoop、YARN、優先權、雲端運算、QoS"
    },
    {
        "resulNum": "2.",
        "title": "OpenStack Hadoop Cluster 系統架構分析之探討",
        "link": "https://hdl.handle.net/11296/eu9xe3",
        "description": "目前許多企業或是研究單位以 OpenStack 為雲端基礎架構建立私有雲，達成資源有效利用，並且讓租戶自我服務及自動化佈署所需要的雲服務資源。在實際運行面上企業與研究單位在導入與建置私有雲時會遇到一些阻礙，最為常見的問題為『IT 管理人員建置、管理雲服務的技術能力』與『建置私有雲服務的預算限制和成本考量』為兩大原因。IT 管理人員除了規劃系統架構外也需要了解該架構的優缺點以及適用的情境、規模大小、未來的可延展性與系統可靠性，因此 IT 管理人員需要精進技術能力與花時間實驗進行各種新技術的研究。但 IT 管理人員需要管理組織現有設備與系統高可用性，實際難在有限時間內分析各個不同系統架構的優劣，並同時兼顧建置系統的預算限制和成本考量。因此本研究主要針對設計幾個不同的雲端運算架構建置 Hadoop Cluster 進行測試，針對所提出之架構進行效能評估與比較分析：• 不同的 OpenStack 架構環境中建立出來的 Hadoop Cluster 系統架構效能優劣。• 驗證目前技術巨量資料系統架構介接外部軟體式儲存裝置作為運算磁碟效能是否仍是不佳的。• 分析不同的雲端運算架構，針對這些架構進行效能比較，並且彙整研究過程遭遇的問題，提供建議企業與研究單位在實際企業導入雲端服務時的建置規模、使用情境，並且分析未來可能會遇到的瓶頸。雖然在技術文獻測"
    },
    {
        "resulNum": "3.",
        "title": "以Hadoop與Hive建構遊戲平台的大數據分析系統",
        "link": "https://hdl.handle.net/11296/bvpdq5",
        "description": "隨著線上遊戲的蓬勃發展，遊戲交易資料的分析與存取對資訊系統是非常重 要的，關聯式資料庫是近幾十年來企業常用來存取資料的資料庫，例如 MySQL[1] 就是解決方案之一。查詢資料的效能是資訊系統關注的議題，關聯式資料庫雖能應付大部份資料 查詢的情境，但當面臨資料庫主機因 CPU 滿載時，要查詢的資料表資料量又非常 龐大時，查詢資料的反應時間就會馬上增加使查詢資料的效能降低。Hadoop[2]是 個雲端運算架構的開源框架，提供適合存取巨量資料的叢集架構。Hive[3]是建構 於 Hadoop 環境下的資料倉儲工具，只要撰寫類似 SQL 的 HiveQL，就能實現 MapReduce[4]，有效率的查詢巨量資料並降低查詢資料的反應時間。本論文以某家遊戲公司(以下簡稱 N 公司)為例，探討關聯式資料庫面臨要查 詢的資料量過於龐大而導致查詢反應時間增加的問題並提出解決方案。N 公司目前 一週大約會產生三千萬筆遊戲交易資料，且有逐漸增加的趨勢，因此使用關聯式 資料庫查詢一週以上的遊戲交易資料，很容易使資料庫因 CPU 滿載而導致效能變 低及查詢反應時間增加。本研究於原系統架構，引進 Hadoop 架構，增加一個「大 數據資料同步模組」將關聯式資料庫資料同步至 Hive 的資料庫，增加一個「巨量 資料查詢服務」來提升查詢巨量資料的效能。實驗結果顯示，引進 Hadoop 架構並 使用 Hive 來查詢巨量資料能提升 N 公司查詢龐大"
    },
    {
        "resulNum": "4.",
        "title": "下一世代Hadoop檔案系統之資料回復",
        "link": "https://hdl.handle.net/11296/geyht2",
        "description": ",,下一世代Hadoop檔案系統之資料回復"
    },
    {
        "resulNum": "5.",
        "title": "以大數據Hadoop Spark平行框架演算進行颱風定量降雨預測之研究",
        "link": "https://hdl.handle.net/11296/9fm9v5",
        "description": "全球每年約有80個颱風生成，以西北太平洋生成的颱風最多也最強，而臺灣正巧處於西北太平洋颱風的主要路徑上，颱風帶來豐沛雨水充填水庫的同時，也造成了各個生活面向的損失，像是農產品產量削減、工商活動停擺、部分地區淹水、颱風降水引發山地土石流等。本研究旨在透過建立颱風降水預測模式預測颱風來臨時之降水量，提前警示臺灣各行各業之人民，及早預防暴雨、評估是否放假，以此減少人民及經濟的損失。本研究使用臺灣北部地區四個測站來建立颱風降水預測模式預測颱風來臨時之降水量。本研究利用深度神經網路(Deep Neural Network, DNN)來建立降水預測模型，並且結合大數據技術Hadoop Spark分散式框架加速模式建立與運算速度，根據不同的資料量設計四種不同的案例(Case0 – Case3)以比較降水預測的準確性。資料來源為中央氣象局1961年至2017年颱風警報單及地面測站氣象資料。本研究根據各個案例及測站設計篩選相關的屬性資料。再根據不同的案例將資料切割分成三組資料集，訓練資料集、驗證資料集及測試資料集，訓練資料集於各案例中用來建立深度神經網路模式，驗證資料集用來找出深度神經網路(Deep Neural Network, DNN)最佳的超參數，測試資料集視為一組獨立資料集用來測試模式是否可以在實際情況中使用。本研究將方法分為兩階段，第一階段利用深度神經網路(Deep Neural Network, DNN)來建"
    },
    {
        "resulNum": "6.",
        "title": "支援資料串流之Hadoop資料服務",
        "link": "https://hdl.handle.net/11296/mk7u3a",
        "description": ",,支援資料串流之Hadoop資料服務"
    },
    {
        "resulNum": "7.",
        "title": "Hadoop Data Service 與 SQL 的整合與在商業套裝資料庫之應用",
        "link": "https://hdl.handle.net/11296/w9c7ru",
        "description": ",,Hadoop Data Service 與 SQL 的整合與在商業套裝資料庫之應用"
    },
    {
        "resulNum": "8.",
        "title": "藉由資料存取位置篩選來改進Hadoop系統效能",
        "link": "https://hdl.handle.net/11296/9nusyp",
        "description": "近年來隨著雲端運算的蓬勃發展，雲端系統普遍為大眾所應用，使用者可以將自己的資料放置在雲端系統上保存，並且可隨時下載或分享給其他人使用。Hadoop是其中成熟發展的雲端平台，Hadoop可以包含大量的計算節點及將資料備份多份到Hadoop叢集裡，而利用此特性的MapReduce可以將龐大的資料分散給叢集裡的多台電腦分工運算，藉此完成單台電腦無法完成的龐大工作。但是MapReduce工作執行時偶爾會遇到讀取工作過度集中於某一台節點讀取的情形，這會使得讀取工作受到變慢，MapReduce工作完成的時間加長。本研究透過獲取每台Datanode的硬碟忙碌資訊並以此篩選傳輸檔案時的節點，藉此可以使MapReduce工作不會受到延宕，使單台電腦的負載量不至於過大，其他台電腦不至於閒置，改善Hadoop叢集的負載平衡，使整體運作效率能夠提高。"
    },
    {
        "resulNum": "9.",
        "title": "植基於 Hadoop 叢集互動式網頁應用系統開發 - 以線上測驗為例",
        "link": "https://hdl.handle.net/11296/xk4m9z",
        "description": "傳統三層式（3-Tier）架構是目前Web應用程式最普遍使用的架構；分別是表示層、應用層，與資料層。此架構若應用於雲端運算平台，具有以下缺點；增加系統開發人員學習大數據資料分析工具時間；應用系統開發套件與雲端運算平台之專案容易發生衝突；替換或升級元件會直接影響應用系統執行效率。本研究開發互動式網頁應用系統結合Hadoop 雲端運算平台（以下簡稱: Hadoop），運用Docker軟體貨櫃技術建立與管理 Hadoop，相對於實體機或傳統虛擬化技術，可減少開發、測試與部署的時間，並以多層式架構（N-Tier）為基礎，提出 Hadoop為核心的五層系統架構，由上至下分別是：負載平衡層（Load Balancing tier）、使用者介面層（UI tier）、應用層（Application tier）、資料存取層（Data Access tier），及資料湖層（Data Lake tier）。如前所述，本研究，開發Hadoop互動式網頁應用系統，以線上測驗系統為例，有效降低建置 Hadoop 環境的成本。並以HDFS 檔案瀏覽介面，簡化使用者在Hadoop繁複的操作流程並可執行大數據分析工具；Pig、Hive、HBase，及 Phoenix。最後，本研究之系統架構，前端、後端，與 Hadoop均可獨立開發與部署，具有良好的擴充性。"
    },
    {
        "resulNum": "10.",
        "title": "藉由布隆過濾器來改善Hadoop記錄資料查詢",
        "link": "https://hdl.handle.net/11296/a9nvqc",
        "description": "由於網際網路的蓬勃發展，伴隨著各種電子形式資料的迅速增長，大數據資料的儲存及計算成了重要的議題。Hadoop 為一個開源的雲端系統平台，其包含的 HDFS 分散式檔案系統 (Hadoop Distributed File System) 及 MapReduce 計算框架，為大數據的儲存及計算提供了一可行的解決方案。大數據常見的應用方式之一，是以純文字形態(Plain-Text)的記錄檔案儲存在 HDFS 中，並使用 MapReduce 框架處理所需的資料，此類的應用特性在於寫入一次、讀取多次。基於此應用方式的特性，本篇論文在於使用布隆過濾器(Bloom Filter)處理記錄資料的特徵欄位，使HDFS系統減少檔案讀取次數，以改善HDFS讀取檔案及MapReduce計算效能。"
    },
    {
        "resulNum": "11.",
        "title": "使用平行和分散計算在Hadoop和Apache Spark資料架構下之大數據特徵選擇演算法",
        "link": "https://hdl.handle.net/11296/d7h78a",
        "description": ",feature selection,,big data,Hadoop,Apache Spark,machine learning,algorithm,minimum-redundancy-maximum-relevance,data mining,使用平行和分散計算在Hadoop和Apache Spark資料架構下之大數據特徵選擇演算法"
    },
    {
        "resulNum": "12.",
        "title": "Hadoop平台分群與關聯規則整合應用之研究-以交通事故嚴重程度為例",
        "link": "https://hdl.handle.net/11296/9gw5h9",
        "description": "Hadoop是一個分散式系統基礎架構，它有MapReduce和HDFS兩大核心。K-means是一個容易實現且常用的分群演算法；Apriori是挖掘頻繁項目集和關聯規則的演算法。許多研究將K-means與Apriori整合應用，在分群階段時有機會將某些感興趣但出現頻率不高的屬性分為一群，進而找出隱藏規則。另外，降低事故發生率一直是交通管理上被重視的議題。本研究將以Hadoop平台的MapReduce和HDFS為基礎，以交通事故嚴重程度為例，探討K-means與Apriori的整合應用。本研究首先對交通事故資料進行預先處理，接著進行資料分群並找出關聯規則，最後做K-means、屬性分群與不分群關聯規則分類整理、綜合整理及受傷程度關聯規則屬性分析。分類整理結果為僅「K-means」分群關聯規則有重複22條，「屬性分群」及「不分群」皆未有重複；綜合整理結果為僅「屬性分群」與「不分群」沒有相同的關聯規則，其他的交叉比對皆有；受傷程度關聯規則屬性分析結果為佔196條關聯規則25%以上的屬性及內容共有6項，這6項對交通事故嚴重程度有顯著的影響。"
    },
    {
        "resulNum": "13.",
        "title": "提升Hadoop Map Reduce運算效能之研究",
        "link": "https://hdl.handle.net/11296/berxkp",
        "description": "根據2012年國際數據資訊公司的調查報告指出，數位資料的資料量在西元2020年時將成長到40ZB左右，相當於全球每人平均擁有大約5000GB左右的資料量，至少需要5顆1TB的硬碟才能夠儲存，若要將這些資料變成有用的資訊就必須要經過資料處理的動作，而如何有效率的處理這些大數據資料是為本研究之動機。為了能夠有效率的處理資料，現在已有許多的大型資訊公司如Facebook、Yahoo與Amazon等都採用Hadoop來處理資料。Hadoop是一個開放式原始碼授權的大數據處理系統，主要的核心技術為Map Reduce，不僅可以建置於商業用的伺服器也可以建置於一般的消費型個人電腦，Hadoop除了可以透過單機建置的方式進行資料處理外，也可以透過將多台機器組合在一起建置成一個Hadoop集群來提升資料處理的速度，雖然透過集群的方式建置Hadoop系統的確可以提升資料處理的速度，但是Hadoop系統中預設的參數設定值只提供系統基本運作的功能，並沒有針對不同的運作環境做最佳化的調整因而導致無法發揮出全部的運算效能，因此本研究透過參數調整的方式有效的提升了Hadoop在進行資料處理時的效能，根據本研究的研究結果，Hadoop在資料處理的效能上最多提升了2.36倍。"
    },
    {
        "resulNum": "14.",
        "title": "ALBERT: 利用自動學習方法優化 Hadoop 執行與資源使用之計算管理系統",
        "link": "https://hdl.handle.net/11296/zwpx9q",
        "description": "Hadoop是一個常用的計算框架，可以在大型商品叢集上提供及時且符合經濟效益的數據處理。它減輕了程式開發者處理分散式程式的負擔，並且圍繞它發展出了一個大數據解決方案的生態系統。然而，Hadoop的作業執行時間很大程度上取決於其運行時配置和資源選擇。Hadoop提供了超過100個作業參數設置，以及雲或虛擬化計算環境中不同的資源實例選項，運行Hadoop作業仍需要大量的專業知識和經驗。為了因應這些挑戰，我們利用深度神經網絡及基於歷史執行數據來預測Hadoop作業時間，並且提出了優化方法來減少作業執行的時間和成本。結果證實，我們的預測方法達到了將近90％的時間預測精準度，並明顯超出了其他三種最先進的基於回歸的預測方法。基於時間預測，我們提出的配置搜索方法和作業調度演算法成功地將單個Hadoop作業的執行時間縮短了2倍以上，並且將處理一批Hadoop作業的執行成本降低2.7倍以上，與此同時，無需額外的人為知識或介入。"
    },
    {
        "resulNum": "15.",
        "title": "基於Hadoop之輕量級資料轉傳系統",
        "link": "https://hdl.handle.net/11296/b6btwg",
        "description": "Hadoop是目前被世界許多大公司與研究機構廣泛使用與討論的大型分散式儲存與運算框架的系統，其儲存系統HDFS(Hadoop Distributed File System)，旨在處理TB級別以上的巨量資料，然而目前除了Hadoop原生檔案系統的操作與使用，還有許多元件與功能，是依循其框架或設計理念，而被研發出能增進HDFS管理效能，或是亦於讓使用者更方便操作HDFS。目前的HDFS主要使用物件導向程式(Object-oriented programming) 程式JAVA撰寫，在使用上，除了系統本身各元件之架構與資料流的運行，需花一定時間了解，其撰寫所使用的程式語言，也是學習上的一項門檻，對於使用Hadoop有更進階需求的開發者，無疑需要累積相當的實力與開發經驗，才能順利在系統上增添功能，惟HDFS在不斷的增加、修正版本後，也陸續提供了許多的框架與API(Application Programming Interface)，讓開發者能省略部分底層設計原型，進而達到快速開發與方便上手的設計模式與技巧。本篇論文中，我們基於HDFS之分散式儲存系統，以及其他常見可用來儲存資料的工具，如FTP(File Transfer Protocol)、HTTP(HyperText Transfer Protocol)、Linux，設計出目的在省略巨量資料平台底層的複雜操作，以目前被廣泛使用且簡易的API，來設計跨不同檔案伺服器的資料轉傳系統，降低HDFS對於使用者入門的障礙，並探討Hadoop與此轉傳系統，建置於單一伺服器的極限與讀寫議題。"
    },
    {
        "resulNum": "16.",
        "title": "Hadoop分散式R運算服務之智慧及動態資源配置",
        "link": "https://hdl.handle.net/11296/b4hfcx",
        "description": "R語言，是當前在資料統計、繪圖常用的腳本語言之一，但R在本身得設計上，卻是以單執行緒運行，雖然目前已經有許多平行化的套件，但此類型平行套間皆以核心數為單位來平行運算，使得面對大量資料下的R使用者需要伺服器等級的環境才得以解決問題。Distributed R Service (DRS)，顧名思義就是將R程式分散的一個服務，是相關研究人員提出的分散式運算框架，用以解決R程式在單機上遇到大量資料處理的問題，簡單來說，就是資源的不足導致運算效率差或工作執行失敗。對R使用者來說，使用DRS只需要懂得定義好一個DRS工作內容，因為DRS對R使用者隱藏了分散式執行的細節，不需要特別去撰寫原本R程式以外的部分，以降低使用者的學習門檻。DRS是建立於Hadoop YARN上的一個應用服務，就像Spark與MR一樣依賴YARN的資源管理分配，DRS也依賴YARN提供的叢集資源管理與分配功能，去建構出適合R執行的工作流程，也進一步提供分散式支援功能如動態分配任務、任務排程、錯誤回復、R使用者自定義函數等等。本文中，將會說明在一個固定資源的工作下，如何解決R任務因記憶體不足而導致工作失敗的問題，與原本資源利用不佳的問題。透過這些設計，讓DRS能更彈性的被使用，給使用者依自己環境的需求，調整相對應的設置。"
    },
    {
        "resulNum": "17.",
        "title": "具通透性之Hadoop資料服務",
        "link": "https://hdl.handle.net/11296/y2s2g2",
        "description": "Hadoop為一計算框架及分散式儲存系統，其儲存系統名為Hadoop Distributed File System (HDFS)，設計用來儲存超大型檔案，卻無法有效的處理大量小資料，目前雖然存在許多方法可以解決小資料的議題，但對於使用者來說需要額外付出相當多的處理步驟，而HBase是建構在HDFS上的分散式資料庫，提供高效率的隨機存取，可以用來解決小資料的問題，但這兩套系統皆需要花費時間學習外且皆使用Java語言撰寫，對於一般使用者來說是個相當高的門檻。本論文提出一具通透性的分散式儲存系統，設計的目的是為了解決HDFS上小資料的議題外，並支援HDFS Interface介面用以相容Hadoop體系相關應用，使得Hive及Spark等專案之使用者不需額外修改程式碼就可以直接使用系統存取資料，同時提供簡易的Web API隱藏巨量資料平台後複雜的操作，讓使用者輕易的透過API，將資料匯入至巨量資料平台。"
    },
    {
        "resulNum": "18.",
        "title": "整合Hadoop與Spark數據分析平台之建構與應用－基於政府公開資料之空氣品質預測為例",
        "link": "https://hdl.handle.net/11296/n8whm6",
        "description": "近年來大數據議題持續發展，隨著監測資料取得的成本逐年降低，以及資料儲存的成本下降。雲端平台的資料儲存技術以及資料分析技術勢必成為未來之重要發展項目之一。本研究基於現有開源軟體Hadoop以及Spark進行整合建立雲端平台，並且提供資料儲存及資料分析使用。在案例上採用政府公開資料做使用，採用環境保護署之空氣品質監測資料做使用，達到政府資料活化應用之目的，且藉由此資料能有效測試本平台在數據分析上之效能及活用性。在資料分析方面採用兩種分析模式進行分析。一是時間序列分析，時間序列分析可使數據藉由自身歷史資訊來建立模型，並且預測為來數據相關數值。二是整合時間序列分析與隨機森林回歸樹之數值預測模式，首先藉由時間序列分析取得資料特徵值之預測數據，再藉由此預測數據放入隨機森林樹所建立之數據模型進行預測。在此種預測模式下，能夠藉由有效數據量的增加，增加模型之準確度，有效提升預測數值之預測。最後探討本研究所建立之平台分析效能，藉由相同的數據在不同版本之隨機森林樹模型建力訓練時間做比較，說明本研究所提供之雲端平台能有效降低數據在分析上之模型訓練時間。"
    },
    {
        "resulNum": "19.",
        "title": "於無硬碟電腦教室實作Hadoop與Spark分散式系統與應用",
        "link": "https://hdl.handle.net/11296/9j474n",
        "description": "科技日新月異，全球資訊化的成果就是電腦普及。以各級學校而言，在近年來推動資訊教育的努力之下，包括政府擴大內需政策對於資訊設備經費的補助，各校對於電腦教室之設備更新中長程計畫之執行，更是不遺餘力，因此大部分學校單位皆有大量電腦設備的存在，加上電腦硬體及網路效能不斷提升， 業界發展出一套管理電腦教室的新型態工具：無硬碟還原系統。因為其特性是對於上課用之系統可以快速部署，因此本研究欲藉此結合電腦教室之設備資源，進行實驗以及利用。大數據為現今資訊產業最熱門的話題，在管理大數據的眾多工具之中，Hadoop與Spark為目前最受企業所推崇的工具之一，因此本研究之宗旨在於，利用電腦教室多台電腦作為節點，提供分布式儲存的方式，將教室電腦安裝大數據工具Hadoop與Spark，搭配“無硬碟還原系統”做快速部署，使電腦教室可以快速成為一個運算大數據之作業平台，提供一個新形態的運算環境，並且測試其效能與增加其應用價值。"
    },
    {
        "resulNum": "20.",
        "title": "應用Hadoop系統架構於生理大數據分析-以心臟衰竭為例",
        "link": "https://hdl.handle.net/11296/6xjkg8",
        "description": "本研究採用OLAP編碼方式，以及用於處理大數據資料的Hadoop為架構，針對心臟衰竭的病患資料，進行分維和預測病況的結點之架構整合。在編碼部分，根據病患的加入順序，結合以個人資訊維、地區維、時間維、感測維、心知識維五大維度去做分層。依照編碼的三大原則，推算出列舉之案例以兩千人為單位的醫療體系將不堪交易量的與日俱增。為解決不確定因子如:突如其來的環境因子造成的交易數據量過多，本研究提出資料蒐集應結合醫學知識為基礎的基於Hadoop的OLAP系統架構，進而降低數據量，從傳統的紀錄方式164.79 GB降低到14GB，相比約少了11.7倍。在基於Hadoop的OLAP系統架構裡面，本研究為強調Hadoop優異的MapReduce計算與分析方式，將以個案的形式描述一個患有心律不規律波型的患者的處理流程。用於分析上應具備的四大流程包括:計數、分類、過濾處理、相關計數。此外還要建立一個造訪資料的流程，以交代初始資料的建置、修改以及運用。本研究列出偽代碼，以及Hadoop在分布式文件系統中運用的map reduce組件之間的訊息傳遞流程和相關的外加功能Hive資料倉庫工具，提供強大的類SQL查詢功能。當中會敘述到基於Hadoop的OLAP系統架構中數個模塊間的使用，以及經過MapReduce運算處理後的新表單。"
    },
    {
        "resulNum": "21.",
        "title": "運用Hadoop雲端運算技術發展細菌metatranscriptomics整合分析平台",
        "link": "https://hdl.handle.net/11296/an8d5h",
        "description": "微生物生態的相關研究可以更清楚地幫助科學家了解環境的改變，越來越多的研究將Metatranscriptomics利用於食品，自然生態，以及人類或動物腸道上等環境進行分析。本研究建立了一個Metatranscriptomics整合分析平台，使科學家能夠更迅速方便地進行微生物生態相關分析。本研究主要是整合Hadoop與序列分析工具，再利用整合後的系統將NGS所產生的序列與全物種資料庫進行比對，得到屬於細菌的序列，將細菌序列與Silva核糖體資料庫比對來區分成核糖體RNA以及非核糖體RNA兩種序列，核糖體RNA的部分做物種分類分析，用於研究環境中改變幅度較大的細菌。非核糖體RNA則進行功能分析，試圖找出這些類群與環境的關係。最後用VM之方式建立虛擬系統整合包來達到簡單安裝的目的。"
    },
    {
        "resulNum": "22.",
        "title": "巨量資料分析平台之建置與評估:於vSphere上部署Hadoop生態圈",
        "link": "https://hdl.handle.net/11296/pt86bz",
        "description": "近年來網路平台發展快速，如社群網路、網路流量、搜尋引擎、線上影音內容、線上交易等資料的產生，快速地累積成巨量資料，若要對這些巨量資料進行運算分析，須借助於分散式運算的技術來完成。目前最熱門的雲端運算平台為Apache軟體基金會所推出的Hadoop開源軟體框架，以及Hadoop生態圈完整的基礎架構並提供分散式運算的環境，適合用於處理和儲存巨量資料。而虛擬化技術作為雲端運算架構的關鍵技術，藉由虛擬化技術的資源排程，動態分配資源給虛擬機器，提高硬體資源的利用率，使資源的調派上更為靈活，而容錯機制可避免硬體在計畫外的停機而造成服務中斷。本論文將使用VMware vSphere虛擬化軟體，在虛擬化環境下部署Hadoop生態圈，並規劃伺服器與儲存設備的網路架構，使用虛擬機器配置Hadoop運算節點，並且部署多組不同節點數的Hadoop叢集，使用資料集進行運算分析，評估各叢集運算的執行效率。"
    },
    {
        "resulNum": "23.",
        "title": "應用SDN分散Hadoop Shuffle流量",
        "link": "https://hdl.handle.net/11296/9y2mxt",
        "description": ",,應用SDN分散Hadoop Shuffle流量"
    },
    {
        "resulNum": "24.",
        "title": "基於Hadoop之GPU叢集的大資料Python平行運算",
        "link": "https://hdl.handle.net/11296/2zdy7z",
        "description": "\n\n,基於Hadoop之GPU叢集的大資料Python平行運算"
    },
    {
        "resulNum": "25.",
        "title": "基於 Hadoop 之網絡資料轉傳服務系統",
        "link": "https://hdl.handle.net/11296/r7aed9",
        "description": "\n\n,基於 Hadoop 之網絡資料轉傳服務系統"
    },
    {
        "resulNum": "26.",
        "title": "改善Hadoop MapReduce負載平衡之機制",
        "link": "https://hdl.handle.net/11296/23jrj8",
        "description": "於此巨量資料時代，諸多資料分析的相關應用均須仰賴平行與分散式運算以處理龐大資料量。MapReduce是一種具有簡單易用、高容錯性、高可擴展性等優點的平行處理框架，近年來被廣泛應用於巨量資料處理；MapReduce有眾多開源實作，其中最知名的為Hadoop。然而，MapReduce在處理資料密集型應用程式時經常遭遇資料傾斜問題，其主因之一即為不均勻的資料分布，例如資料集內容呈現Zipf分布。Hadoop預設之雜湊分區函式在處理此類資料集時，大多數情況下均無法將工作量均勻分配給各reducer，亦即不同reducers間負載不平衡，且未盡可能地減少各reducer需透過網路傳輸其輸入的資料量。為了降低資料傾斜對MapReduce效能造成的負面影響，本論文將前述問題分成兩種情況，這兩種情況各有其欲達成之目標。接著本論文提出一種具優先權之負載平衡機制，此機制結合蓄水池抽樣法、二階段貪婪演算法，以及一個分割reduce keys演算法，並將資料區域性、優先權等概念融入方法中，以達到前述兩種情況的目標。其執行流程是先利用抽樣獲取資料集內的資料分布情況，接著考量各reduce key出現的次數與其分布在各資料節點的資料量，然後將所有reduce keys逐一分派給適當的reducer處理。實驗結果顯示，本論文提出的具優先權之負載平衡機制除了能有效地減少各reducer需透過網路傳輸其輸入的資料量，更重要的是使各reducer間達到負載平衡，因此其執行時"
    },
    {
        "resulNum": "27.",
        "title": "以平行基因演算法於Hadoop平台上建立投資組合",
        "link": "https://hdl.handle.net/11296/md7799",
        "description": "由於經濟的不景氣以及亞太金融的擴展，越來越多的人們開始學習投資理財的觀念，但金融市場與投資工具越多樣化，投資者將面對更加複雜的投資環境，因此要如何才能夠有效的選擇投資目標則是一件相當困難的事情。另外由於網路的發達，形成了巨量資料的產生，已經無法利用以往的人工方式來蒐集分析獲得需要的資訊，因此像是Hadoop這種分散式框架的平台因應而生，透過其分散式的框架可以將數量龐大的資料分散儲存在不同的電腦上分開計算，在計算完成後再呼叫計算結果到主機端，提供給使用者有效的資訊。因為台灣股票市場的股票種類眾多且繁雜，對於投資者來說選擇投資標的物是一種非常困難的問題，以及在技術指標的運用上，投資者會因為對於指標的不熟悉，而無法得到正確的評估結果，另外投資者會透過投資組合來分散投資風險，但是在資金分配比例上也是一個問題。本研究透過Hadoop平台分散式的框架，來儲存台灣股市大量的交易資料，並結合技術指標與平行化基因演算法的方式，針對台灣股票資料進行篩選與分析，根據每個投資人不同的投資條件設定，找出最適合投資者所需要的投資標的物。本研究預期貢獻就是建立一個投資組合篩選模型，透過此模型，投資者可以輕鬆便利的輸入其設定的投資條件，透過資料的計算與篩選，將合適的投資標的物形成一個投"
    },
    {
        "resulNum": "28.",
        "title": "基於HADOOP實作動態分析資料表關聯調整資料放置方式",
        "link": "https://hdl.handle.net/11296/9x98x9",
        "description": "在面對巨量資料(Big Data)的分析時，關聯式資料庫已經無法負荷如此龐大的資訊量。Hadoop可以透過HDFS儲存大量資料，並且透過MapReduce分析巨量資料。由於HDFS的高容錯性和高擴展性，許多企業都開始將資料轉移到Hadoop中，利用雲端運算環境處理大量的資料。而Hadoop對於資料的儲存，是將資料以資料區塊作為區分，以隨機存放的方式，平均分散到叢集中，並沒有考慮資料的相關性。使得在執行分析任務時，有相關性的資料被分散到不同的節點中，增加了需要透過網路交換資料的成本，對於效能有很大的影響。本篇論文提出了在將關聯式資料庫轉移到Hadoop時，當資料從關聯式資料庫轉移到Hadoop時，將儲存的資料區塊從原先只是隨機選擇儲存地點，改進成透過檢視運算節點效能和資料表的參照關係，提供較佳的儲存策略，使得有相關性的資料區塊放置在一起，使得查詢資料時能夠降低資料的找尋成本，讓整體執行效能獲得提升。"
    },
    {
        "resulNum": "29.",
        "title": "Hadoop叢集在Linux Docker上的實作研究",
        "link": "https://hdl.handle.net/11296/y2f2mk",
        "description": "研究如何處理巨量資料已成為近年的趨勢，在沒有專門大型主機的情況下，可以透過多台PC架構成分散式系統來儲存及處理資料，其中一種為使用開放原始碼的Hadoop軟體，為了要使叢集能夠更快速的擴充，本研究將Hadoop叢集系統與Docker虛擬化技術進行結合，使用Docker容器建立Hadoop叢集，以Docker在容量與執行速度上的優勢，提升替Hadoop叢集加入新節點的效率。本研究以Linux Ubuntu 16.04作業系統為起點，經由各軟體套件的安裝與調整網路設定，建構一個所有節點皆使用Docker容器的分散式的運算叢集，在完成以Docker容器建立好的Hadoop叢集之後，使用真實資料並模擬情境來運行Hadoop的三個相關軟體:Pig、Hive與HBase，以處理資料搜尋來測試Pig、Hive與HBase能不能正常運作。"
    },
    {
        "resulNum": "30.",
        "title": "實作結合虛擬化部署的Hadoop生態系統入口網",
        "link": "https://hdl.handle.net/11296/9g5dey",
        "description": "現今巨量資料在許多領域如資訊、金融、醫學等的發展皆具有越來越重要的地位，因此巨量資料的研究、分析、處理等的需求也越來越多。目前用於巨量資料的環境大部份是使用Hadoop或Spark來進行處理分析，但此類環境的建置需具備有一定的專業知識與對系統的熟悉度，對一般使用者來說有一定的難度。另此類環境的操作皆須以輸入指令的方式進行操作，對習慣使用圖形桌面環境的使用者存在學習使用指令操作的門檻。為了降低使用者操作巨量資料工具進行處理分析的門檻，本論文利用Liferay Portal實作了結合Hadoop與Spark巨量資料平台的網頁使用者介面，並更進一步將巨量資料平台與網頁使用者介面整合於虛擬機映像檔中，讓使用者能夠快速方便地部建巨量資料平台與執行巨量資料的工作。希望提供便利的網頁使用者介面的同時，減少對工作時運算效能的影響，且降低建立巨量資料平台的難度與所需時間。本論文亦進行了透過使用指令與透過網頁使用者介面執行巨量資料處理工作的效能比較，使用的是HiBench的測試套件，測試在提供使用者方便性的同時，網頁使用者介面對巨量資料處理工作時的效能所造成影響的程度。另外，由於相關研究的需要，在本環境中亦建置了OpenCV的環境，也實際使用粒子圖像測速法程式驗證OpenCV函式庫在本系統中的可用性。"
    },
    {
        "resulNum": "31.",
        "title": "Hadoop MapReduce應用於中文資料檢索之研究",
        "link": "https://hdl.handle.net/11296/qqe5ax",
        "description": "資訊科技相關軟硬體日新月異，人們可以使用各種資訊科技產品及網際網路，從事各式各樣的活動。然而運用資訊科技所帶來的方便，也造成資料快速的累積。如何處理龐大的資料量並找出其中人們所需的資訊，成了一個值得研究的議題。本研究以Hadoop平台中的MapReduce和HDFS為基礎，利用MapReduce計算模型應於中文資訊之關鍵字檢索與全文檢索。本研究首先將中文資料進行預先處理，利用詞頻-反轉文件頻率(TF-IDF)方法計算字詞權重，依據字詞權重擷取出每篇文件中的關鍵字。對於使用者輸入的檢索字詞，關鍵字檢索將其與每篇文件的關鍵字進行比對，而全文檢索則將其與文件內容進行比對，透過相似度計算檢索出與檢索字詞相關的文件。實驗結果顯示，中文資訊檢索的檢索表現，關鍵字檢索平均精確率為99.29%、召回率為82.64%及F指標為88.22%；全文檢索平均精確率為82.64%、召回率為99.29%及F指標為88.22%。本研究的精確率、召回率與F指標等3種指標的平均值皆高於相關研究。"
    },
    {
        "resulNum": "32.",
        "title": "使用隱含式回饋基於關鍵字之推薦服務於Hadoop平台",
        "link": "https://hdl.handle.net/11296/ngn679",
        "description": "推薦系統為資訊的使用帶來極大的便利性，不論是購物、觀看影片還是閱讀文章都能使用推薦系統進行推薦，然而，當有新的用戶或項目加入就會因缺少其相關訊息造成推薦上的困難，稱之為冷啟動問題，一般解決冷啟動問題的方式是在推薦流程前加上一個信息收集的階段，而信息收集的方法又分為顯性回饋和隱性回饋，過去的研究著重在顯性回饋，也就是要求使用者提供信息文件以便於分析其喜好，但這會降低系統的友善性，而隱性回饋則是系統主動收集使用者的行為作為推薦所需的資訊，隱性回饋省去了使用者提供初始信息的步驟，改為由系統自行解決冷啟動的問題，大幅減少了系統使用的複雜度。本論文將行動APP使用紀錄當作隱性回饋作為使用者的初始信息，藉由爬蟲取得豆瓣電影的電影資訊，將其存入MongoDB資料庫，再輔以wiki的資料庫數據計算使用者的信息與電影資訊的相似性，將其相似性作為參考以矩陣分解的方式分析使用者的喜好，希望藉由新用戶的APP使用紀錄來分析出所需的信息，以此來解決信息量不足所產生的冷啟動問題。除此之外以使用協同過濾的電影推薦為例，實作出一個架設在Spark叢集採用隱性回饋作為信息收集方式的推薦平台，以行動APP使用紀錄來獲取使用者喜好資訊，再根據這些資訊以矩陣分的方法來推算出一組預測評分，從而對使用者進行推薦"
    },
    {
        "resulNum": "33.",
        "title": "基於Hadoop與MongoDB雲端系統之電力訊號品質分析及效能改善",
        "link": "https://hdl.handle.net/11296/5xmvm7",
        "description": "本論文研究利用Arduino擷取電力訊號之DAQ技術與Node.js處理電力訊號品質之相關演算法，探討如何設定雲端伺服器主機並調整Arduino傳輸時間間距，以適當地將電力品質相關資訊傳輸到遠端主機進行分散式儲存與運算任務。本論文以Nginx平衡負載器配合Node.js網站伺服器作為資料傳輸之網路連線入口，接受多受測地點同時傳輸；並以MongoDB作為後端雲端資料庫，以穩定執行運算與儲存相關工作；Hadoop Hive 配合Hadoop HDFS執行效能分析，使得整體系統的儲存方式、運算模式及工作分派等機制更為有效率。Hadoop及MongoDB是大數據(Big Data)處理技術中同時具備運算與儲存功能之雲端系統，因此可以建置大量(Volume)、多樣(Variety)與快速(Velocity)的電力訊號品質監測所需大數據處理功能平台，本論文研究設計雲端分散式運算平台之統計分析技術，所執行的雲端系統建置架構也可以適用目前物聯網的普遍應用環境，同時，相關系統效能分析原理也可以適用一般大數據應用可能遭遇的問題。"
    },
    {
        "resulNum": "34.",
        "title": "以樹莓派為基礎的Hadoop Cluster之執行時間改進方法",
        "link": "https://hdl.handle.net/11296/snp86t",
        "description": "物聯網(Internet of Things)的興起，成為未來網路通訊科技重要的發展趨勢。因此物聯網相關的研究與應用也越來越受到重視。由於物聯網裝置的數量龐大，會以相當快的速度產生相當大量的資料，也就是大數據(Big data)。因此，如何快速有效率的去分析、處理並應用這些大數據是相當重要的挑戰。這些大量資料通常需要及時的處理(Real-time processing)，然而，如果透過傳統的雲端運算(Cloud Computing)，將資料傳送給遙遠的雲端處理，再將處理好的資料回傳，會耗費較多的時間。此外，使用者要連上遠端的大型資料中心才能存取服務，如果所有人都共用一個資料中心，或產生資料的節點太多，會因為佔用大量網路頻寬，造成資料中心的負擔過重。因此出現了功能相似，但運算能力較弱的霧運算(Fog computing)。資料處理則是更接近用戶終端裝置，這麼做的原因是可以化解可能出現的網路塞車現象，有效減輕網路流量，資料中心的運算負荷也跟著減輕。在本論文中，以九台低功耗的微型控制器，樹莓派三代B版(Raspberry Pi 3 Model B)，架設了一個小型運算叢集(Cluster)。此叢集使用了阿帕契的分散式檔案系統(Apache HDFS: Apache Hadoop Distributed File System)，並改善樹莓派叢集執行MapReduce的執行時間。此外，本文透過四種方法以及三種Master-Slave Model，分別對照五種檔案大小來做對照觀察比較。由於在預設環境下執行MapRedce的第一種方法無法有較短的執行時間，因此進一步提出另外三種方法，第二種"
    },
    {
        "resulNum": "35.",
        "title": "以科技接受模式探討Hadoop導入 對企業經營之影響",
        "link": "https://hdl.handle.net/11296/6m6kv4",
        "description": "近年隨著與資訊科技的進步與網路應用普及，企業運用資料量遽增，如何有效管理與分析大數據應用技術之重要因素，如何將資料整合並擷取出具有價值的資訊，以提供企業決策者分析問題與判斷決策的依據，已成為現代企業建立競爭優勢不可避免的挑戰。因此本研究以科技接受模式為基礎來探討Hadoop（雲端運算分散式叢集系統）導入對企業經營在大數據的應用及資料的整合影響分析，並檢測對於相關產業所擷取出的資料是否對企業經營策略發展產生影響。研究中以量化的問卷調查方式進行，並採用SPSS22.0統計分析方法，調查對象為相關業界及學界資訊人員。問卷內容分成三大部份，包含基本屬性、購買特性與運用影響特性等。利用回收之有效問卷以假設檢定模式來歸納Hadoop使用與資源有效配置之關聯性及使用者之接受程度及相關決定性。研究結果顯示在科技接受模式下，大數據技術之實際應用使用態度與導入之影響對於使用者知覺有用有正向影響、知覺易用性對使用態度有正向影響。使用者行為效能方面其使用態度對行為意圖亦有正向影響，未來對企業之知識管理策略的發展具有良性影響，分析結果將可作為大數據技術產業對產品實用性與知覺易用性提供應用參考，俾提供相關產業經營與制定策略之參考。"
    },
    {
        "resulNum": "36.",
        "title": "以田口方法及自動化方式優化Hadoop效能參數之研究",
        "link": "https://hdl.handle.net/11296/z62wbw",
        "description": "雲端時代的來臨導致資料處理量增加的速度變得非常快，所以需要一些有別於傳統的方法來處理這些巨量的資料。而Hadoop正可用於儲存並計算這些大數據，不論是作為資料探勘、處理索引、記錄檔…等需要大量數據的工作，都可以利用其中的MapReduce來得到更好的效率和擴展性。MapReduce為一個分散式處理框架，將資料分成多個任務並同步執行，每個工作節點均可用來分擔並完成作業。Hadoop系統開啟時，會先導入相關的參數設定，而任務應有一組最為合適的參數組合設定使得MapReduce能有最快的完成時間。但由於Hadoop系統在一啟動後便無法更改參數設定，如要做參數的調整必須要完整的關閉Hadoop並再次重新啟用，可是參數的設定又多達190種，如果要一一手動嘗試所有的參數組合將會非常的耗時，相關論文多是利用實驗模擬的方式或是參考少量的參數設定利用暴力法來手動尋找最佳設定，但一樣是曠日廢時。本論文實作出一個自動化的方式從開啟Hadoop系統、讀入程式所設定好的參數配置，最後將相關效能參數傳回主程式提供調整依據。搭配上述的自動化機制，本學位論文使用了工業上的田口方法做實驗設計，實驗模擬結果顯示此方法可以使用最少的執行次數即可得到近似最佳參數設定組合的效果。未來實際運作上，則可先取出部分資料作為測試使用來做參數的調整與設定，並利用此機制獲取"
    },
    {
        "resulNum": "37.",
        "title": "Hadoop平台建置自學教材開發",
        "link": "https://hdl.handle.net/11296/vrs8n8",
        "description": "現今資料從傳統結構化轉至半結構化、甚至非結構化，且數量正以極快速度地成長，巨大量資料已成為現階段一股新興潮流及關鍵競爭因子。在知識爆炸時代，如何從所蒐集的巨量資料來萃取知識，及利用巨量資料分析模型來提升競爭力、並展現價值，為協助各行各業提升效能、達到具競爭力的目標，巨量資料分析應用是主要關鍵。於此研究為自學教材開發，藉由文獻探討及資料蒐集，設計一份符合適用於分段、與環境限制下，自學的課程教材，實際應用在課堂上讓同學依開發之教材實作，學習Hadoop平台建置，提供一個實際之各式應用端分析工具平台建置，讓非資訊專業人士，能透過本論文提供之自學教材，建置符合所需之合適巨量資料分析工具平台，進而找尋巨量資料在其應用領域及機會。本次研究取得兩梯次共31位人員，實作後所回收的結果並分析，確認使用此教材，讓學員對”了解巨量資料分析工具--Hadoop相關技術”具正向回應，另外分析出學員背景不同，所回應的要求也不盡相同，可作為後續研究。"
    },
    {
        "resulNum": "38.",
        "title": "基於樹莓派之互動式Hadoop雲端資源管理介面之研究",
        "link": "https://hdl.handle.net/11296/4s8b8c",
        "description": "本研究主要探討樹莓派單板電腦在有限的硬體資源下，系統管理者如何用智慧型行動裝置，快速佈署與管理Hadoop的分散式資源，並可依照運算需求動態調整叢集架構。本研究佈署Hadoop過程，逐一分析安裝步驟所需要執行的指令，從中探索網頁與Hadoop互動的關鍵因子，並提出以Node.js為橋樑，結合SSH與WebSocket兩種通訊協定，搭配jQuery前端網頁相關技術，將Hadoop複雜的安裝步驟予以整合、簡化，並實作「基於樹莓派之互動式Hadoop雲端資源管理介面」。Hadoop執行環境的初始化、叢集佈署、啟動、停止，及檔案上傳至HDFS等基礎功能皆已完成。同時，亦整合前端網頁JavaScript相關程式框架，以虛擬開關的顯示方式，抽象地將前端網頁與Hadoop XML組態檔做轉換，系統管理者現在可以透過智慧型行動裝置快速地維護Hadoop組態設定。本文以「SSH通訊協定」搭配「WebSocket通訊協定」作為互動基礎，結合Node.js、JavaScript相關的網頁開發技術，並以此設計「互動式介面」，能夠快速地規劃及重新調整HDFS與YARN的環境設定，解決樹莓派佈署與管理Hadoop的問題。"
    },
    {
        "resulNum": "39.",
        "title": "iFedMR：支持迭代MapReduce應用的聯邦式Hadoop系統",
        "link": "https://hdl.handle.net/11296/hjh6h6",
        "description": "\n\n,iFedMR：支持迭代MapReduce應用的聯邦式Hadoop系統"
    },
    {
        "resulNum": "40.",
        "title": "Hadoop在資源機制之最新工作排程政策",
        "link": "https://hdl.handle.net/11296/mpjgr7",
        "description": "no"
    },
    {
        "resulNum": "41.",
        "title": "針對 Hadoop 在嵌入式異質多核心平台之低功耗設計流程",
        "link": "https://hdl.handle.net/11296/nuu8t2",
        "description": "Hadoop是一種廣泛採用的分佈式處理架構。 Hadoop的設計方向是針對每個計算節點由傳統CPU配上記憶體架構的系統組成,且具有良好的跨平台性。不過,這樣的架構不適合在嵌入式異質多核心平台上有效率的利用。主要的挑戰是由於Hadoop的環境和嵌入式異質系統之間資料的收集和管理方式不同。為了解決上述的問題,本文提出了一種工作流程,使Hadoop的應用程序,能夠有效地利用分佈式嵌入式異質多核心系統。在不修改Hadoop資料儲存規則的情況下,能夠讓異質多核心平台更有效率的計算,以高效率的方式來收集和管理細粒度的資料。使用主成分分析(PCA)作為範例,結合所提出的設計方法在Tegra K1集群上執行資料大小16K×16K的矩陣,進而提升了6.4倍的效能,並證明出嵌入式異質多核心群集的功耗效率比相較傳統的PC集群更高。"
    },
    {
        "resulNum": "42.",
        "title": "醫療影像系統(PACS)使用Hadoop存儲方法之研究",
        "link": "https://hdl.handle.net/11296/76fz5u",
        "description": "PACS系統是現代醫學發展而生成的醫學影像檔案存儲及傳輸的基礎，但是隨著醫學影像成像技術的迅猛發展，成像的清晰度的大幅度提高及展現出來的方式多樣性，使得醫療影像資料存儲量變為海量級的，顯然醫療影像的存儲成為了大數據的問題。Hadoop HDFS分散式叢集存儲系統使用廉價的通用硬體進行橫向擴展，解決了傳統存儲因縱向擴展而導致的天花板效應。以HDFS存儲系統為基礎，將PACS架構其上，這樣既解決了醫療影像存儲的可靠性、安全性、易擴展等問題，更為重要的是為之後的大數據和雲計算奠定了基礎。HDFS存儲系統和PACS系統的結合在技術和成本上具有很大的挑戰性，本文從HDFS存儲系統不能存儲小檔案的缺點，基於Hadoop SequenceFile檔案格式設計了一套符合實際應用場景的混合存儲架構系統。這套系統包含HDFS存儲系統、SequenceFile格式的H-DICOM檔案和NFS傳統存儲。其核心是HFHSC（H-DICOM File Hadoop SequenceFile Converter），主要用於DICOM圖像和H-DICOM格式的相互轉換。測試結果表明此架構可以滿足大量醫學影像資料的快速存取和處理需求。"
    },
    {
        "resulNum": "43.",
        "title": "基於Hadoop之分散式多層次三角網格索引系統",
        "link": "https://hdl.handle.net/11296/v78mww",
        "description": "目前，在地球科學、地理、天文等領域的研究或應用中，需要分析處理空間中的物件，而物件的位置通常是在球面上以赤經及赤緯來記錄。為了使儲存及管理這些物件更有效率，需設計出一套良好的球面空間索引系統。隨著科技的進步以及資料長久的累積，各個領域需要分析的資料量越來越多，導致在傳統單機應用的環境下，硬體無法負擔。因此，本論文建構了分散式球面空間索引系統，以多層次三角網格（HTM）為模型，運用Hadoop的MapReduce運算框架，設計出相應的資料結構及分散式演算法。不但能儲存及管理大量球面空間物件，還能提供分散式應用程式快速索引與查詢的功能。本論文之分散式球面空間索引系統，是使用泛星巡天計劃Desktop Virtual Observatory (DVO) 資料集，而經由實驗將系統中各項參數對效率的響影做比較，供使用者參考，可以針對不同的系統環境及不同的應用需求進行調整，達到系統的最佳效率。"
    },
    {
        "resulNum": "44.",
        "title": "在Hadoop 環境下以自建本體 進行使用者興趣偵測與文件推薦",
        "link": "https://hdl.handle.net/11296/md78h2",
        "description": "推薦系統是一種常見的資訊過濾系統，不論對於商業或是個人而言都是一項非常重要的技術。為了針對使用者做出客製化的推薦，時常會藉由使用者輪廓(User profile)來記錄使用者過往的行為，而透過本體(Ontology)來建立使用者輪廓的推薦系統可以做出更準確且多元的推薦。本研究主要可分為兩部份：自動建立本體與建立使用者輪廓和推薦，首先分別將英文文件與中文文件藉由系統自動建立出本體，再將使用者行為對應到本體上建立出使用者輪廓並進一步進行管理和推薦。另外，本研究加入聚合式階層分群來改善過去研究建立本體時過度分群的現象。並且為了應對未來資料量的成長，本研究透過Hadoop 分散式環境來提升系統效率與未來的可擴充性。在實驗的部分，本研究採用Amazon 網路書店的英文書籍簡介和博客來網路書店的中文書籍簡介作為資料集，模擬在不同語言與不同狀況下使用者的興趣變化來測試本系統的推薦品質。而實驗結果顯示出本研究成功改善推薦的品質，並且在未來有能力處理更大量的文本資料。"
    },
    {
        "resulNum": "45.",
        "title": "於 Hadoop Yarn 平台上建置平行化的 FP-Growth 演算法",
        "link": "https://hdl.handle.net/11296/sx2k68",
        "description": "當今網路與資訊爆炸的時代，資料透過網路產生的速度更是呈指數性的成長，將資料分析成為有價值的資訊是現今大家所關注的議題之一。Hadoop 為當今資料探勘的熱門平台。Hadoop 的優點是採用分散式的檔案管理，能將大資料集切割成資料片段，動態地分配給不同的節點。搭配 Hadoop 的 MapReduce 的程式寫法，將一個工作切為數個子工作，交付不同的節點處理，以加速分析處理問題的效能；因此，Hadoop 平台適合處理巨量資料集。 FP-Growth 演算法為不產生候選項目集的高頻項目集探勘演算法，在許多領域中具有很高的實際應用價值。然而傳統的 FP-Growth 只能處理小資料集,在面對巨量資料集時，處理的時間與效能較不理想。本研究針對對傳統的 FP-Growth 演算法，利用 MapReduce 運算技術,將 FP-Growth 演算法平行化於 Hadoop Yarn 平台上。實驗結果發現新的Yarn 架構，在處理不同資料集時，比舊的 Hadoop 架構具有一定的優勢。"
    },
    {
        "resulNum": "46.",
        "title": "在 Hadoop 架構下的高效能大數據馬賽克影像運算之方法",
        "link": "https://hdl.handle.net/11296/9j75sf",
        "description": "隨者網路的快速發展，科技的日新月異，人們也從使用傳統的底片進行攝影改為使用記憶卡的方式來儲存影像。再加上成本低廉、網路的普及社群網路的盛行，數位影像的數量是爆炸般的成長，因此數位影像逐漸地變為巨量資料的其中一個議題。本研究提出一個使用影像特徵改良 K-Medoids 分群法針對影像資料庫進行分群。透過影像特徵來改良K-Medoids分群法是為了縮短分群的時間，得以達到更快的讓分群的結果達到一個穩定的狀態。並將分群結果輸出為編碼簿。透過編碼簿可以降低馬賽克影像的計算複雜度以及運算時間。本研究有三個主要的目標。第一，利用影像特徵改良K-Medoids分群法降低分群的時間。第二，利用改良的K-Medoids演算法所輸出的編碼簿可以降低馬賽克影像的計算複雜度。第三，雖然本研究的實驗結果影像品質略低於Szul 等學者的方法，但透過實驗結果可以發現，本研究的方法大幅地降低馬賽克影像的執行時間，同時保留不錯的影像品質。"
    },
    {
        "resulNum": "47.",
        "title": "基於Hadoop之非MapReduce的大資料R平行運算",
        "link": "https://hdl.handle.net/11296/78kf93",
        "description": "R語言是一種主要用於統計分析、繪圖、資料探勘的腳本語言。R以豐富的函數套件庫、活躍的開發社群與其套件的擴充性著稱。並且R本身是開放原始碼，亦有以編譯的執行檔版本可在多種平台下執行。隨著R在統計分析的領域越來越熱門，其在運算效能上的要求也逐漸成為重點。R在本身設計上是以單個執行緒運行，而目前已經除了官方平行套件外仍有許多支援平行運算的套件。但是此類型的平行套件均以核心數為單位進行平行運算，而這項特點使得R在面對大資料運算的情況下都是在單一伺服器等級的電腦上進行高負載的運算。在此篇論文中，我們提出一個新的分散式運算架構的來解決R在面臨大量資料運算時的不足，設計的目的在於移植R程式至分散式環境執行並隱藏分散式的細節。該運算架構是建立於Hadoop YARN上的一個運算模型，使用YARN提供的叢集資源管理與分配並建構出適合R執行的工作流程與管理。YARN的核心概念是將叢集資源管理與運算工作管理委任給不同的元件負責，由一個全域的資源管理ResourceManager (RM) 與每個任務都唯一的元件ApplicationMaster (AM) 負責。而這項設計實做了AM的流程並定義了符合R運算的控制流程，目標是排程並分派R的任務到由RM提供的運算資源單位Container中執行並且由AM去控制工作流程，來達到分散式執行R。並且除了提供基本的執行"
    },
    {
        "resulNum": "48.",
        "title": "基於健保資料預測中風之研究並以Hadoop作為一種快速擷取特徵工具",
        "link": "https://hdl.handle.net/11296/wutx98",
        "description": "隨著電腦運行速度的提升、儲存技術的進步以及通訊技術的發展等原因，使人類可以使用的數據量大為增加，因而使得大數據的研究興起。在大數據研究興起的同時，同樣也造就了資料探勘領域的發展，讓人類得以從大數據中提取到有用的資訊。若能將大數據研究用於醫學領域，將會是可以達成改善照護、拯救生命以及降低開支等裨益人類甚多的研究。但隨著資料量不斷日益增長，使用一般單台機器循序式資料處理工具會耗費掉大量的時間。在耗費大量時間的同時，又會衍生其他因時間過慢產生的問題。若可使用分散式的平行運算框架，讓多台機器一起運算資料，將可以大幅減少運算時間。過去諸多研究表明，服用常被開立於治療憂鬱症或相關精神健康症狀的SSRI藥物，會增加中風的風險。本論文研究基於此些研究結果，使用全民健康保險研究資料庫進行醫療衛生資料分析，對曾經服用過SSRI相關藥物的人使用機器學習建模預測中風，其中資料處理使用分散式運算工具Hadoop加速處理速度。對比本實驗室之前的方法，同一組資料在預處理提升了約35倍的速度，擷取特徵提升了約585倍的速度，提升效果顯著。處理完的資料使用GBDT為分類器進行資料分析，因處理速度大為提升的情況下，得以擷取更多的特徵。藉由檢驗前20位最重要的特徵，最終結果顯現了我們的模型對比於本"
    },
    {
        "resulNum": "49.",
        "title": "運用獨立資源分派策略解決Hadoop分散式架構於虛擬化模式之衝突",
        "link": "https://hdl.handle.net/11296/2cwazw",
        "description": "雲端是近年來廣泛應用的技術架構，藉由雲端運算的強大計算能力，使我們可以迅速處理海量數據，分析出想要得到的資訊。在雲端運算平台中，Hadoop是最為廣泛的分散式架構平台，可以在伺服器叢集間使用MapReduce編程模型，將應用程式分割成許多小部分，每部分都能在叢集的節點運算或重新執行，用於運算處理巨量資料。Hadoop的分散式檔案系統HDFS，能在叢集中儲存所有節點的巨量資料，而且有容錯能力，使得節點發生故障時運算仍能正常執行，且資料有極高的可用性。虛擬化技術是一種將電腦的各種實體資源創造成抽象化的虛擬資源，讓電腦資源的使用變得更靈活，而達到降低成本、簡化管理等目的。Hadoop結合虛擬化技術，可以得到虛擬化便於資源部屬、節點建立、資料轉移、資料備份與復原的優勢，使得管理成本降低。然而Hadoop架構與虛擬化技術結合，會因為虛擬化的資源共享特性產生衝突，導致讀寫能力降低、網路流量集中造成瓶頸，使Hadoop效能低落和導致容錯力降低，喪失原本Hadoop分散式架構平行處理的優勢。本論文以解決Hadoop運用於虛擬化的衝突為目標，我們會定義Hadoop於虛擬化產生的衝突，制定解決衝突的策略，由策略的方向設計虛擬化Hadoop架構，逐步將衝突點解決並提升虛擬化Hadoop的效能，證明本論文的策略能解決Hadoop於傳統虛擬化的衝突，保留Hadoop的容錯、處理效能及可擴充性等優勢，同時"
    },
    {
        "resulNum": "50.",
        "title": "應用平行K-means演算法建構股市決策支援系統於Hadoop平台",
        "link": "https://hdl.handle.net/11296/pj58hs",
        "description": "股市投資一直以來都是一項熱門的投資方式，其投資方法主要分成基本分析、技術分析、籌碼分析。在技術分析中，投資者會根據不同的技術指標來投資股票，但技術指標種類繁多，時常讓投資者不知道該使用哪種技術指標來投資，導致投資結果並不理想。本研究以TEJ資料庫做為股市資料來源，將以Hadoop平台為基礎讓股票先透過技術指標公式平行運算後，接著將K-means演算法套用於MapReduce框架上，藉此將股票作分群並同時提高運算效率，最後將分群結果定義決策後，再推薦投資者作買進或賣出之決策。本研究之決策支援系統將採用技術指標的公式及K-means演算法來建構其中的模式管理子系統部分，並將分析出的結果呈現出來供投資者作參考。"
    },
    {
        "resulNum": "51.",
        "title": "建構於可程式化邏輯板實現硬體加速之Hadoop 叢集用於資料探勘演算法",
        "link": "https://hdl.handle.net/11296/e3e6cb",
        "description": "由於物聯網的興起，人們經由網路與伺服器交換的資料量越來越龐大，隨著大數據的演進，如何從巨量資料中挖掘出有價值的資訊，是現今的重要課題。因此資料探勘演算法被廣泛使用在各個領域上。而如何處理這些海量的資料以及分析不同的資料型態成為大數據會面臨到的問題。為了解決儲存設備與運算能力的限制，分散式系統和雲端運算近年也越來越普及，透過多個伺服器叢集執行平行化的運算，克服CPU運算速度的瓶頸；此外，藉由多個伺服器的串聯來增加儲存的容量，彌補單一設備空間不足的問題。為了提升運算的效能，在處理任務的時候，可以藉由硬體加速平台來分擔運算的負載。硬體加速平台最常見的有圖形處理加速器(GPU)和可程式邏輯陣列(FPGA)，通常擁有數量眾多的運算單元，用來執行高密度且獨立的運算並達到運算平行化。本論文針對巨量資料的儲存平台與運算能力的增進，提出一個軟硬體整合的方案，在Hadoop系統串聯以FPGA為基礎的硬體加速平台，利用Hadoop叢集的分散式檔案系統(HDFS)以及MapRdeuce的平行運算優勢，再藉由網路分享器提升擴充性，建構一個用於資料探勘演算法的Hadoop與FPGA整合的加速平台。我們使用在資料探勘中最常見的K-means分群演算法以及KNN最近鄰居分類演算法來呈現此整合加速平台的優勢。"
    },
    {
        "resulNum": "52.",
        "title": "以Hadoop為基礎的雲端破密系統",
        "link": "https://hdl.handle.net/11296/m3wbbh",
        "description": "近年來，雲端運算的蓬勃發展主要倚靠網路頻寬的提高與硬體設備效能的提升。目前最為重要的則是分散式運算系統，例如：Hadoop、Spark。分散式運算系統是將資料分配到多個節點中進行運算及處理，最為理想的狀況下假設原本1台電腦運算100GB的資料所花費的時間為1000小時，再使用分散式運算擁有1000個運算節點系統下，理論上花費的時間只需要1個小時就可以完成。現今多數破密系統是以單主機執行的形式進行破密運算，即便密碼擁有高複雜度多數都能被破解，但可能需要花費數十小時或是數天的破解時間，例如：暴力破解法、字典破解法。暴力破解法優點在於不佔用任何硬碟空間，但缺點為需要花費大量時間使用CPU運算；字典破解法的優點與暴力破解恰恰相反，優點為只需要讀取字典檔案破解，佔用電腦運算資源較少，但缺點為需要非常大量的硬碟空間儲存字典檔。本論文提出一個基於Hadoop為基礎的雲端分散式破密系統，結合兩種破解方式提升破密時的效率。讓使用者透過網頁介面輸入Hash值，系統將讀取預先儲存於HDFS的字典檔案進行破解，透過MapReduce分散式運算進行字典破解，加速整體運算的效率。若有成功破解出明碼，將結果輸出；若無破解出明碼，則將採用暴力破解的方式逐字推算出明碼。將破解結果透過網頁介面呈現給使用者。本系統運用Hadoop分散式系統將字典破解與暴"
    },
    {
        "resulNum": "53.",
        "title": "以Hadoop分散計算為方法之駭客攻擊偵測專家系統之研製",
        "link": "https://hdl.handle.net/11296/pfbuv3",
        "description": "隨著資訊時代的來臨，網際網路亦成為資訊快速交換的媒介，電腦病毒的散播途徑也隨之在全球各地肆虐起來，然而駭客攻擊的技術與手法也持續地在進步，其遭受攻擊的範圍、目標也因此而逐漸擴大，雖然目前已經有可以偵防駭客攻擊的工具，但在面臨網路駭客攻擊威脅時，也可能無法有效地阻擋駭客的攻擊。本研究針對企業提出一套判斷網路駭客攻擊的專家系統，並建置於Hadoop框架技術之私有雲分散式運算的雲端環境中，專家系統擬定4項風險之各項規則來分辨該連線行為之風險程度，並結合MapReduce的分散式計算型式能力，來提高專家系統在資料分析與計算的效能及品質，系統將會研判有風險的連線行為，並即時將該連線之風險程度及防護建議通知給管理員進行安全防護處理，藉此為企業打造一個安全的資訊安全環境。"
    },
    {
        "resulNum": "54.",
        "title": "使用Hadoop技術建立巨量資料分析處理模型：以空氣汙染資料為例",
        "link": "https://hdl.handle.net/11296/2x632j",
        "description": "近年來，由於巨量資料呈現爆炸性的成長，資策會MIC表示，軟體市場趨勢將由「行動應用、巨量資料、社交媒體、雲端運算」等新興科技整合創新服務所驅動，展望未來。而在巨量資料的時代裡，如何從龐大且雜亂的資料中，找出有效的隱藏資訊來提升組織營運或是應用的效率是相當重要的。因此本研究規劃基於Hadoop技術的概念，藉由分散式運算的技術整合HDFS、MapReduce等相關元件，以及參考空氣汙染的重要影響因素，其中將風速加入考量是基於空氣運動需要動力，風為壓力及科氏力(Coriolis)與摩擦力等互相平衡所產生的結果，所以觀測空氣污染的擴散上，須以風速作為判斷的依據，並使用SQL Server Analysis Services (SSAS)的資料採礦功能建構出空氣汙染的模型分析架構，最後產生淺顯易懂的資訊、圖表、評估數據，以大陸冷氣團南下及中國霾害造成PSI及PM2.5濃度超標為例，進行資料推導分析，其結果將建議有心臟、呼吸道及心血管疾病的成人與孩童，應減少體力消耗，特別是減少戶外活動，而這些相關建議提供給使用者作為預防之依據或讓企業及相關單位作為使用，本研究透過定時蒐集的大量數據，利用有效的資料分析方式並結合Hadoop分散計算的能力達到快速處理與分析巨量資料之目的。"
    },
    {
        "resulNum": "55.",
        "title": "實現Hadoop叢集HDFS檔案之歷史版本保存",
        "link": "https://hdl.handle.net/11296/2my673",
        "description": "雲端平台在近幾年已經被大量應用在不同領域，其中Hadoop是最為被廣泛使用的平台環境。最初Hadoop提供一個簡單、可擴充、有效率的雲端運算與雲端儲存架構，隨著大數據分析與快速運算的需求，Hadoop新功能與支援的快速進步，它的生態系統發展與應用方式已經越來越豐富，效能也改善得越來越良好。Hadoop分散式檔案系統HDFS(Hadoop Distributed File System)為Hadoop預設檔案系統，HDFS的結構主要分為兩個部份，分別是NameNode(名稱節點)與DataNode(資料節點)。基本的HDFS會配置為一個NameNode主機與多個DataNode主機，NameNode用於管理所有檔案的metadata(檔案屬性資料)、命名空間(namespace)以及儲存區塊(block)清單與位置的資訊，DataNode負責儲存這些檔案區塊，並將檔案區塊複製多份給其他DataNode主機群。在Hadoop初期的發展期間，HDFS為了滿足儲存大型檔案的效能目的，犧牲了一些UNIX檔案系統的一些基本功能，因此初期HDFS並不允許使用者任意修改檔案內容，直到append與truncate功能出現，它們也只是有限度的修改原來檔案的內容。同時Hadoop 2.2正式新增了快照功能(snapshot)，它可以特定的完整備份整個目錄的檔案，多次的定時快照就會有歷史檔案備份的效果。但若是在兩次指定時間的備份之中有多次差異內容，快照就無法備份到中間的差異之處。在以前，想要能夠取得檔案內容的更完整歷史版本，只能增加快照的次數，但是一般用途中需要密集備份的目的檔案數量在整個快照當中所佔的比"
    },
    {
        "resulNum": "56.",
        "title": "實現雲端運算Hadoop叢集儲存資料之差異分析",
        "link": "https://hdl.handle.net/11296/8kn66w",
        "description": "隨著網路的蓬勃發展，雲端運算在近幾年快速的熱門起來。在眾多的雲端平台軟體當中Hadoop 被廣泛使用。Hadoop 有著穩定且實用性高的特性，並且提供一個簡單且易使用的平台處理大量的檔案。Hadoop 是一個分散式系統， 其預設的分散式檔案系統為HDFS(Hadoop Distributed File System)。HDFS 主要是由一台NameNode 和多台DataNode 所組成的叢集(Cluster)。NameNode 主要的功能是紀錄儲存檔案存放位置和檔案的相關資訊，而DataNode 為真正存放檔案的地方。NameNode 會將檔案切割成多個區塊(block)，再將切割後的區塊存放在多台DataNode 上，並把每個區塊複製多份放在不同的DataNode 節點上。但這些備份都儲存在同一個叢集內，若所在的位置遇到火災或其他不可抗拒之因素導致資料損毀，會讓使用者損失重要的資料。為了確保資料不會因為這些問題遺失，我們會將資料備份到不同的叢集上。然而在備份資料的過程中，可能因為網路斷線或其他不可預期之異常原因傳送失敗，傳送者會無法得知資料在兩個叢集是否一致。為了解決這個問題，我們產生一個HDFS Namespace Numbering Tree(HDFS NSNT) 建立出一個樹，再藉由NSNT 建立出HDFS Namespace Numbering File(HDFS NSNF)，NSNF 會列出檔案的詳細資訊。最後我們會將兩個叢集分別建立出NSNF檔案，並比較兩個NSNF 內的欄位資訊，再將兩個NSNF 不同處列出，讓使用者可以快速找到兩個叢集整個檔案或部分檔案不同之處，增加可靠性。"
    },
    {
        "resulNum": "57.",
        "title": "實現雲端運算 Hadoop MapReduce 之分級服務",
        "link": "https://hdl.handle.net/11296/4e68cp",
        "description": "Hadoop是一個能夠廣泛應用及具有高延展性的平台軟體，也是一個能夠處理大量資料和擁有高容錯性的分散式系統。如同其它應用軟體一樣Hadoop必須建置在作業系統上執行，並且透過作業系統才能和硬體互相通訊協調。隨著雲端運算（Cloud Computing）和巨量資料（Big Data）的出現，支援雲端服務軟體執行的雲端平台也就變得非常重要。Hadoop針對執行的工作有提供資源分配的機制。在此機制下提交的工作群被分配成不同等級的資源分配順序，具有高資源分配的工作較之低資源分配者可以有較高的機會獲得資源，並且優先執行工作。然而在相同等級的工作群中並無法指定特定工作優先執行。因此在忙碌的Hadoop環境中，即使是具有高資源分配的工作，由於同等級排隊等待資源的工作很多，也無法保證其能較快速得到資源以提早完成工作。本研究將提出讓特定使用者在Hadoop環境下可自行設定優先執行工作的機制，並且在作業系統中加入之前已改善的CFQ硬碟排程器的優先權機制，以及在記憶體置換機制中加入優先權的研究，使得具有優先權的程式在Hadoop系統中執行時，可以優先獲得資源，並且在作業系統中可以增加運算與I/O執行的速度，提升程式執行的效率。在本研究的實驗裡，我們在Hadoop系統中同時執行多個應用程式以模擬一個忙碌的環境，並且在多個程式中設定特定的程式具有優先權，經過實驗的"
    },
    {
        "resulNum": "58.",
        "title": "參考狀態指標之Hadoop分散計算效能分析與評估",
        "link": "https://hdl.handle.net/11296/24245v",
        "description": "Hadoop分散式運算架構為資訊系統帶來分析大數據組的解決方案，而虛擬化技術的發展，將運算節點以VM形式建構也是業界尋求系統整合的方向之一，儘管可達到彈性分配網路效能與硬體資源，但虛擬機器卻難以比擬實體主機的運算效能，也成為Hadoop叢集虛擬化的一大瓶頸，而管理者也難以評估雲端平臺虛擬化後的效能衝擊。為此，本研究以Hadoop為主體建構分散運算叢集，系統將串連異質伺服器運算資源，採用HBase為主要的資料庫儲存系統，同時運用Hive、Sqoop等套件實現異質環境資料交換能力，將上述架構為基礎運作於虛擬/實體Hadoop平臺上。為了能有效評估叢集運算的效能表現，本研究基於現有研究之效能模型進行整合，並以此計算模擬效能值，與實測數據進行分析比較，驗證該模型之可用性。結果顯示，調整參數的效能模型適用於本研究架構，接著參考虛擬化對Hadoop叢集運算的影響要素，提出適用於虛擬化Hadoop運算叢集的效能模型，並以CSI評估機制動態因應負載變化修正模型，以確保叢集負載不均衡的情境下仍能保持模型的有效性，並進行多組相異條件之測試分析，探討虛擬化技術運用於雲端系統平臺的改善方案，確保Hadoop在虛擬化環境下運作能發揮最佳效能。"
    },
    {
        "resulNum": "59.",
        "title": "針對大數據分析之建構於可程式邏輯板Hadoop系統設計",
        "link": "https://hdl.handle.net/11296/96ey99",
        "description": "由於大數據時代的來臨，與大數據相關的機器學習演算法已被廣泛的使用在各個領域上。受限於儲存設備和運算能力，隨著資料量的不斷膨脹，在單一運算設備如個人電腦上處理機器學習演算法已不切實際。本論文提出一個由嵌入式系統所建構的平行運算叢集，並在上運行Hadoop系統作為處理大數據的方案。另外，透過軟硬體協作的設計方法，更進一步地利用FPGA來加速在Hadoop中執行的運算。在硬體層級中，提供了多個可配置的基本運算模組。使用者可在軟體層級將所需要的運算交由韌體，並透過韌體層級的協作來組織所需要的硬體完成計算。軟硬體的搭配使運算叢集有更強大的運算能力和更快的運算速度。在本論文中，我們採用了Mini-ITX開發套件來架構Hadoop叢集。Mini-ITX是一塊同時具有CPU和FPGA的開發板。運行FPGA時脈於120MHz，CPU時脈於667MHz。在運行奇異值分解於Hadoop的案例中，相比沒有使用硬體加速的情況，使用硬體計算約可得到約7.9%的加速。若以特殊應用積體電路(ASIC)完成硬體設計並運行於更高的時脈，硬體加速方法可獲得更佳的效果。"
    },
    {
        "resulNum": "60.",
        "title": "在軟體定義網路下建構與設計Hadoop叢集於Docker平台",
        "link": "https://hdl.handle.net/11296/2u22nv",
        "description": "由於現今的網路發展迅速，現代社會正以不可想像的速度產生大數據，無處不在的社會和商業活動源源不斷地產生各種資料，若要對這些大量的資料進行分析處理，通常也需要借助雲端運算平台來處理。Hadoop是目前最常見且實際運用在大規模商業環境上的雲端運算平台之一，強大且完整的基礎架構可以減少大量的雲端架構開發的時間，大量部署時也相當迅速。雲端運算是一種基於網際網路的運算方式，通過這種方式，共享的軟硬體資源和資訊可以按需求提供給電腦和其他裝置。若要將共享的軟硬體資源可以按需求提供給其他電腦和裝置，則必須使用虛擬化技術，虛擬化技術可以將一台實體主機的硬體資源轉換成共享的運算資源，其主要的目的是單一主機上執行多個虛擬主機。當需要擴充系統運算能力時，則是以一個虛擬主機為單位來擴充。本研究的目標是希望藉由Docker容器虛擬化的特性，能夠針對Hadoop叢集運算節點的運算資源做出較好的分配，因此我們將探討在同樣的機器上節點數目與容器所配置的運算資源之間的關係，網路流量對於Hadoop叢集運算影響，最後觀察是主節點配置在效能相異的機器上所造成的差異。"
    },
    {
        "resulNum": "61.",
        "title": "以軟體定義網路改善Hadoop叢集之運作效能",
        "link": "https://hdl.handle.net/11296/3n4z3y",
        "description": "由於現今網路發展迅速，巨量資料的時代已經來臨。全球各大企業與組織紛紛改採雲端運算模型來解決他們所面臨的諸多問題。雲端運算的龐大計算與儲存能力來自於大型資料中心，其中運行的巨量資料處理核心工具則多數為Hadoop MapReduce。相關研究指出資料中心透過MapReduce運算框架所產生的中介資料交互傳遞(Shuffling)行為造成網路壅塞現象，直接影響到運算工作的執行效能。針對這個問題，已有一些研究初步驗證了結合軟體定義網路技術將是一個可行的解決方案。換言之，若能將MapReduce排程機制與軟體定義網路結合，藉由動態調整網路資源，將能有效提升Hadoop叢集運作性能。因此，在本研究中，在SDN的網路環境架構下執行Hadoop MapReduce的分散式運算，利用SDN可控制網路頻寬的特性，將Hadoop Shuffle的封包導入頻寬較大的Flow Entry，以加快Shuffle的執行速度，進而改善Hadoop執行MapReduce的效能。本研究設計四組實驗來證明利用SDN可以明顯改善Hadoop MapReduce的效能，在實驗過程當中額外加入其他的封包干擾MapReduce的運算，其結果顯示加入封包干擾的情況下，加速Shuffle封包的處理也可以明顯降低MapReduce執行的時間。最後，本研究針對Hadoop設計一個SDN App，在SDN網路環境之下，建立、刪除Flow Entry基本上都是透過終端機來操作執行，透過這個SDN App使用者可以方便快速的執行建立、刪除Flow Entry的動作。"
    },
    {
        "resulNum": "62.",
        "title": "評估與改善資料網格、YouTube與Hadoop YARN工作執行與資料傳輸效能之研究",
        "link": "https://hdl.handle.net/11296/ke38a6",
        "description": "近年來有許多不同的分佈式計算與儲存系統，例如：資料網格 (data grid)、YouTube 與Hadoop YARN系統，分別被提出與被用來解決複雜科學計算與儲存、分享視訊以及處理龐大資料與多種應用程式 (applications)之問題。因此，在上述之系統中頻寬耗費與工作執行之效能是為重大之議題。其中，在資料網格中許多專家學者提出不同的資料複製演算法來縮短在資料網格中之檔案傳遞時間，進而改善資料存取效能與減少頻寬耗費，但是目前所提出之資料複製演算法都沒有考慮到使用者對數據檔案存取之行為 (data access pattern)，因此導致這些複製演算法都沒有辦法有效改善檔案傳遞時間、資料存取效能與頻寬耗費。而YouTube利用了分佈式快取記憶體 (Memcached) 來加快整個視訊的搜尋與存取，當Memcached儲存空間已滿時，YouTube將採用最久未使用快取置換機制演算法 (least-recently-used cache replacement algorithm)，即以最久沒有被存取之視訊作為替換。然而，YouTube採用LRU進行視訊置換有可能導致增加網路頻寬之耗費與延長視訊取得之時間。另一方面，新一代的Hadoop YARN系統本身提供了不同的排班演算法，來執行多種不同之應用程式排班，進而達到高資源利用率與公平分享資源之原則。然而，在Hadoop YARN中，不同的排班演算法在不同之佇列結構下，執行混合多種不同應用程式時之執行效能，並沒有詳細地被評估。因此，為了解決上述問題，本博士論文中我們將先提出一個資料複製演算法稱"
    },
    {
        "resulNum": "63.",
        "title": "以Hadoop MapReduce叢集架構設計改良式平行化分群演算法",
        "link": "https://hdl.handle.net/11296/xhmnbw",
        "description": "　　分群演算法可以不用事先知道每一筆資料的類別，運用其演算法的特性將相似的資料歸類為同一群，進而尋找出群體特徵與關連的一種資料探勘技術，經長時間發展，已有許多更有效率或者更精準的演算法被提出，同時亦有學者將著名的分群演算法K-Means以及Clustering LARge Application (CLARA)等，將其重新設計成可執行於MapReduce的分散式處理架構，使其分群算法可進行巨量資料的分群探勘，使其可進行巨量資料的探勘。　　本研究將學者所提出之平行化的分群演算法透過MapReduce分散式處理架構實作，找出潛在的瓶頸，並嘗試將其改善，以達到更有效率的進行巨量資料探勘之目的。　　本研究在改善過程中，提出以原始資料集合平行化與以取代群心集合平行化的兩種平行化方式使PAM分群演算法可執行MapReduce分散式處理架構，並且透過不同資料總筆數、不同分群數量與不同叢集節點數量等可能影響執行效能之相關參數進行實驗，用以評估出分群效率較好的平行化方式。並以平行化PAM分群演算法將其設計於改良式的平行化CLARA演算法中，再透過取樣資料總筆數、分群數量、維度大小、叢集節點數量等可能影響執行效能之相關影響因子以不同參數設計出多組實驗，使傳統的平行化CLARA演算法與改良後的平行化CLARA演算法進行效能比較，藉以評估改善之效能。"
    },
    {
        "resulNum": "64.",
        "title": "基於Hadoop MapReduce叢集設計平行化二元分類演算法",
        "link": "https://hdl.handle.net/11296/fu84aw",
        "description": "在現今單機電腦環境已經無法有效率的分析大量資料的同時，Hadoop運算平台之可儲存與分析之特性有著明確的重要性。對於大量資料分析過程而言，資料探勘的演算法應用是其中重要的一環。而本次研究為了解決二元分類演算法SVM之時間複雜度過高的問題，改良一二元分類演算法，於分散式平行化運算框架中達到加速篩選分類資料的效果。主要利用MapReduce程式框架之平行化處理特性實現此演算法並成功運行於Hadoop運算平台上，在使用相同資料集進行訓練分析的情形下，大幅降低了執行運算時間。"
    },
    {
        "resulNum": "65.",
        "title": "運用Hadoop雲端運算技術分析宗教信仰對物質濫用之影響",
        "link": "https://hdl.handle.net/11296/x84wc9",
        "description": "宗教信仰對民眾的身心靈與生活行為有很大的影響力，而物質濫用一直是全球各國重要的社會議題，更是影響身心健康的重要問題。另一方面，Hadoop雲端運算的分散式架構能夠快速處理大量資料，是資料分析的重要工具與應用趨勢。本研究應用Hadoop技術探討居住於美國之民眾的宗教信仰與物質濫用間之相關性，使用美國衛生服務部(HHS)物質濫用與心理衛生服務局(SAMHDA)的藥物濫用及健康調查(NSDUH)資料庫，擷取2004至2013年，總計共有558,703筆資料。以Hadoop的分散式檔案系統(HDFS)以及平行計算程式設計模型(MapReduce)為系統架構，結合Apriori關聯規則探勘進行分析，建立宗教信仰與物質濫用的關聯模型。研究發現，有宗教信仰與有菸草濫用及無非法藥物濫用有重要的關聯性；而無宗教信仰是患有酒精濫用或非法藥物濫用的重要關聯因素，在有非法藥物濫用的關聯規則中，其他重要的相關因素包含有酒精濫用、12-17歲、未婚、男性、高中尚未畢業、白種人。本研究運用Hadoop雲端運算技術之分散式架構，對比傳統單機伺服器，可有效地縮短分析資料所需之兩倍以上的時間，預計更大量的資料可有更好的運算效率。本研究成果可供國內在物質濫用相關領域研究之參考。"
    },
    {
        "resulNum": "66.",
        "title": "Hadoop雲端環境下最佳化演算法效能之比較研究",
        "link": "https://hdl.handle.net/11296/m6tj8d",
        "description": "過去有一些學者為了解決學習障礙鑑定的問題，分別利用了基因演算法、PSO以及API搭配APPS等最佳化演算法，並結合類神經網路，且將之實作於Hadoop雲端環境之下，來對學習障礙做分類預測，並且各自都有不錯的結果，但這些方法都是在不同的環境和配置下來進行運算，因此本研究將整合各式方法於相同的Hadoop雲端環境之下，並對Hadoop參數和平行任務數量作調整來比較各方法之成效。此外，過去學者相關研究所使用的資料集皆侷限在學習障礙的資料集，因此本研究將另外加入從UCI資料庫取得的威斯康辛乳癌資料集來進行實驗，並與其它曾使用該資料集的相關研究來做比較與探討。本研究發現，透過Hadoop參數來調整節點上任務數量的分配，能夠增加運算的效能，經調整過後，比起預設還快上約2倍，其中基因演算甚至達到2.67倍。在三種方法的探討與比較部分，本研究發現無論是在學習障礙的三個資料集，或是乳癌資料集，API搭配APPS的最佳化演算策略相對於其他方法來說皆有著較好的結果。另外，本研究實驗之任務數量最多只到16個，族群數量最多也只到300，因此本研究建議，未來也可以加入更多的機器，增加族群數和任務數，在更大規模的情況下去運算，也許能有著更佳的結果。"
    },
    {
        "resulNum": "67.",
        "title": "跨叢集之聯邦Hadoop分散式檔案系統",
        "link": "https://hdl.handle.net/11296/9y95em",
        "description": ",,跨叢集之聯邦Hadoop分散式檔案系統"
    },
    {
        "resulNum": "68.",
        "title": "Hadoop異質環境下動態集群整合鄰近搜尋之工作排程",
        "link": "https://hdl.handle.net/11296/e6j939",
        "description": "隨著網路的蓬勃發展、雲端環境的成長、網路資料量爆炸性的遞增，雲端運算成為分散式系統中近幾年來炙手可熱的名詞，MapReduce是雲端運算中一個很重要的架構，而Apache Hadoop則是其中一個實現MapReduce且較廣為人知的雲端運算平台。在大型的數據中心執行任務時，不同的任務往往需要使用到不同的資源，但Hadoop本身預設的排程是採用First-Come-First-Service (FCFS-先到先服務)策略，這可能會造成資源利用度的不平衡。隨著各方學者針對工作排程的研究與改進，從DMR演算法修改成JAS、JASL、甚至DJASL。從同質環境與工作深入考量至異質環境與異質工作，利用工作的分類對應至相應的佇列，而JAS及DJASL在資源利用度方面都有一定成效的提升，且DJASL更針對資料區域性做考量有效降低額外的網路傳輸流量，但美中不足的是DJASL在有效的提升資料區域性的同時對於工作執行效能並未能有明顯的成長。因此，在本文中我們提出了一個新的工作排程方式叫做DGNS，利用集群以及鄰近搜尋的概念，以綜觀的方式同時考量MapReduce(計算)以及HDFS(資料儲存)層面，除了有效地平衡資源利用度的問題。可以有相仿的高資料區域性並且能擁有較好的效能表現。"
    },
    {
        "resulNum": "69.",
        "title": "改善Hadoop公平排程器之效能",
        "link": "https://hdl.handle.net/11296/e587xt",
        "description": "雲端系統是支援處理巨量資料的重要技術，不只提供無隔閡的存取空間，更提供同時快速處理大量資料的需求，因此，我們使用Hadoop系統來做MapReduce的運作，實作雲端的應用。此篇，透過修改Hadoop公平排程器的技術來提升整體運作效能。分成眾多層面做參考因素，提出了Job分類、Pool資源分配、先進先出Job排序、公平排程Job排序、動態調整Delay Time以及動態調整Job Priority的機制，藉由這些方法對系統當下的情況進行條件判別，讓實際參考因素的價值提高，有效快速地透過各種篩選和動態調整，挑出可以優先獲得系統運算資源的工作，讓系統整體資源分配盡可能達成最有效的使用率。最後此篇提出之方法和原始公平排程器的方法一起實驗測試，分別比對同時不同種類、數量的工作時平均執行時間的長短。此外，除了前述兩種公平排程器之外，再加入先進先出排程器一起測試混合Jobs工作的測試，比較整體平均執行時間的長短。藉由兩種實驗比較出此篇所提出之公平排程器能有效減少整體平均工作之運行時間，改善了原始公平排程器的弱點，進而促進公平排程器在系統中效能的提升。"
    },
    {
        "resulNum": "70.",
        "title": "結合GPU與多重鏈路協定提昇Hadoop/MapReduce效能之研究",
        "link": "https://hdl.handle.net/11296/73ujv3",
        "description": "隨著巨量資料時代的來臨，雲端運算的議題備受矚目，使得開源軟體Apache Hadoop逐漸受到關注，目前已有許多知名大企業使用Apache Hadoop來處理大量資料，如:Yahoo與Facebook等，他們藉由Apache Hadoop來處理日漸增加的大量資料，並從中獲得巨大的效益。Apache Hadoop中有兩個主要架構，分別是HDFS（Hadoop Distributed File System）與MapReduce，Hadoop提供了一個分散式運算環境，能夠將資料切割成許多的資料區塊，並分配給大量的電腦來儲存與處理，藉由結合大量的叢集機器來提升運算效能，而Hadoop/MapReduce發展至今已經藉由大量專家與學者所提出的方法將其日漸完善並得到大幅效能的提升，但是在如今科技與技術不斷的進步之下，MapReduce運算效能的提升似乎已經遇到一個瓶頸，且容易由於網路環境狀況的變化影響到MapReduce運算的效能表現，因此，本論文提出以近年來興起的Graphics Processing Unit (GPU) 運算技術與Multipath TCP (MPTCP)多重鏈路協定結合到Apache Hadoop的環境之中，藉由結合GPU運算減少CPU運算工作的負擔，並加快Map工作的運算速度，再經由MPTCP減少MapReduce運算過程中所產生資料的傳輸時間。經由常見的Terasort、WordCount及PiEstimate等Hadoop效能比較程式來進行實驗與測試以驗證所提方法的效能。所獲致的實驗與測試結果得知：GPU運算以及MPTCP協定的加入確實能夠有效提升Hadoop MapReduce的運算效能，以及有效提高網路傳輸的頻寬，並減少了分散式運算工作所需的時間。"
    },
    {
        "resulNum": "71.",
        "title": "基於Hadoop之網際網路訊務萃取器設計與實作",
        "link": "https://hdl.handle.net/11296/ake336",
        "description": "網路封包為網路資料的傳輸單位，我們可以藉由網路封包來分析網路協定、效能或是除錯。當研究人員在大型的網路節點(例如，學校、公司等)收集網路封包，在研究上將面臨巨量資料的問題，其導致無法迅速且有效地分析封包。本論文提出一個基於Hadoop的網際網路訊務萃取器來解決巨量資料(Big data)問題，它能夠萃取出使用者感興趣的訊務、重新排序封包並且放置於資料夾中，以利於進一步的研究。MapReduce是Hadoop [1]資料運算的核心，為了運用MapReduce運算架構來實現網際網路訊務萃取器，我們考慮它的運作流程和特性，解決並實現萃取器的設計議題。最後我們在實驗中證實，我們的萃取器是可以正確地萃取出特定的封包串流(flow)，而且藉由Hadoop叢集架構的延展特性，使這個萃取器具有處理巨量封包的能力。"
    },
    {
        "resulNum": "72.",
        "title": "Hadoop之專利佈局與技術發展預測之研究",
        "link": "https://hdl.handle.net/11296/qxau65",
        "description": "專利地圖是技術研發人員於技術前端研究和提案時很有助益的專利分析工具，然而，一個研發提案在實施之前，通常會花費幾年的時間來確定研發方向是否正確，以及如何達到技術目標。本研究以Hadoop雲端運算技術主要專利權人之技術功效矩陣以及其技術演進，進而分析Hadoop技術之專利佈局與技術發展預測。本文除了Hadoop之專利技術趨勢分析之外，還針對主要利申請人之專利家族進行申請歷程分析，建構專利家族的策略性地國際佈局規劃；此外，在預測方面，選擇預測霍爾特指數平滑法與Gompertz曲線預測未來專利申請數，另外，本文以人工歸納主要專利權人之Hadoop專利技術與功效分析，並找出主要專利權人IBM、Cleversafe和Yahoo三者之共同研發趨勢，進而完成Hadoop技術之研發方向分析，更以此作為我國之相關產業未來進行專利國際佈局及技術發展之借鏡。研究結果分析可獲得以下總結：(1) Hadoop技術目前處於技術成長期，且專利件數及申請人數仍持續增長；(2) Hadoop技術領域之專利申請人分佈相當分散，其中，前二十大主要專利申請人佔總專利申請量之42%；(3) Hadoop技術領域之專利權人以IBM首，其技術分佈為分散式運算、資料辨識和優先權及排程技術；(4) 根據霍爾特指數平滑法與Gompertz曲線之預測結果，2014年專利件數年增率介於22%至44%；2015年專利件數年增率則是介於12%至31%；(5) Hadoop技術在台灣尚未發展成熟，台灣亦不是Hadoop技"
    },
    {
        "resulNum": "73.",
        "title": "雲端運算Hadoop架構下離峰時間資料讀取之節點能源管理",
        "link": "https://hdl.handle.net/11296/xzh7yh",
        "description": "隨著雲端計算技術的發展，效能更是發展的重點，但是效能的提升受限於硬體設備，當效能無法有效的提升的時候，如何節省耗能就變成了重要的課題。本論文是利用具有分散式運算特色的Hadoop架構，擁有專用的分散式檔案管理系統HDFS，以及使用一種能夠將大量資料做平行處理的MapReduce計算框架，在此架構下進行能源消耗的節能測試。參考多種節能方法後發現，其中針對節點進行調度管理的節能方法Green HDFS對於節能擁有較好的效果，GreenHDFS是由Hadoop下的分散式檔案系統 HDFS演變而來的一種節約能源的資料分塊設計，本篇論文透過百度統計的網民上網時段分布圖資料，從而得知普遍的網路使用尖峰與離峰時段，由於尖峰時段資料讀取量過高，若是將節點休眠可能不但沒有達到節能的效果，反而要付出更多的能源代價，所以針對使用者資料讀取離峰時間下的節點進行重新分配管理以節約能源。從尖峰時段進入離峰時段後資料量讀取量應該會漸漸降低，所以節點就有閒置的可能，將可能閒置的節點進入休眠狀態，讓剩下的節點進行資料處理，並且在資料量大或者是進入尖峰時間時才去喚醒休眠節點。實驗結果表明，比起原本的 GreenHDFS執行任務時的耗能，在離峰時間下將可能閒置節點進入休眠狀態之後，可以有效的降低整體的21%能源消耗。"
    },
    {
        "resulNum": "74.",
        "title": "Hadoop MapReduce環境中使用改良的LZO演算法配置以提升資料傳輸效能",
        "link": "https://hdl.handle.net/11296/pa99nj",
        "description": "隨著網際網路的發展，各種連網裝置使生活更加方便。但是資訊的產生越來越快，傳統的資料庫和軟體工具漸漸地無法處理大量的資料。為了解決資訊爆炸所造成的困擾，企業需要達成減少資訊成本的目標，一種嶄新的軟體服務模式與資訊架構革命正以撲天蓋地之姿席捲全球，那就是雲端運算。Hadoop是一種開放式軟體框架，用於儲存數據和在硬體集群上執行應用程式的工具。MapReduce在Hadoop中擔任重要的並行運算，而MapReduce的處理過程分三個步驟：Map(主要是處理分割的並行任務)、Combine(為了提高Reduce的效率)和Reduce(把處理後的結果匯總起來)。Map任務的輸出需要寫入到硬碟中並透過網路傳輸到Reduce節點，在此過程中，MapReduce的I/O總會造成計算上的負載。為了解決這個問題，本論文提出了在Hadoop MapReduce環境中使用改良的LZO演算法配置，因為使用預設的LZO壓縮法產生的output，不支援分割成block，也就是說如果把此檔案當作MapReduce的input，那麼MapReduce只會使用一個Map來處理此input，這樣就無法利用整個集群的並行處理能力，從而導致運行時間變長。本文將在Reduce端使用不同的LZO壓縮編碼，使其輸出支援分割成block，讓MapReduce可以直接讀取，減少CPU的計算負載，並經實驗結果證明，MapReduce執行的總耗時將比沒有做修改的方法減少10%~20%的資料傳輸時間。"
    },
    {
        "resulNum": "75.",
        "title": "Hadoop系統參數優化",
        "link": "https://hdl.handle.net/11296/36x7bw",
        "description": "在當前big data的時代，Hadoop系統對於分析和應用大數據有著至關重要的作用，我們既希望能夠把Hadoop系統參數能夠調節到最佳的狀態又希望能夠在不花費更多在硬體的更新上。因此我的碩論的主題選擇在Hadoop系統參數的優化，在這裡主要針對希望優化的效能是在於減少單一任務的執行時間。我採用的是三段式模型：（1）是在眾多參數中找到對於系統影響最大的參數，根據map和reduce分開觀察並選出20個參數作為我們主要要調節的參數；（2）是建立系統時間的預測模型，根據這20個參數去搜集更多的任務執行的時間和相對應的參數作為我們建立模型的基礎，運用機器學習的方法去做建模並且選擇出最適合的三層式模型；（3）是建立系統的優化模型，每次優化機會在設定的參數範圍內隨機選取出來參數，並且把它放到之前建好的預測的模型去預測其執行的時間，經過我設定好的優化模型最終會找到一個執行時間最短的參數組合。我總共選擇了4個程式，經過以上的方法組合去驗證。"
    },
    {
        "resulNum": "76.",
        "title": "Hadoop 於異質平台之資源管理系統",
        "link": "https://hdl.handle.net/11296/pz8txn",
        "description": "Apache Hadoop近年來的蓬勃發展廣泛用在巨量資料的應用上, 但 Hadoop 系統框架在CPU上所遇到的效能瓶頸時常為人所詬病, 如果要將 Hadoop 應用程 式移植到圖形處理器上達到效能提升的目的, 程序員必須要花很多額外的心力。 在這篇理論當中我們將利用Aparapi 程式庫來做到將 Hadoop 應用程式移植到圖 形處理器上執行, 並且探討 Hadoop YARN 框架在異質性平台上的資源管理。"
    },
    {
        "resulNum": "77.",
        "title": "基於Hadoop平台之分散式權重式字尾樹暨天文時序性資料分析系統",
        "link": "https://hdl.handle.net/11296/5kr44p",
        "description": "隨著科技的發展，泛星計畫（Panoramic Survey Telescope And Rapid Response System，Pan-STARRS）中所觀測到的資料量也隨之增長，而儲存設備成本降低，也讓天文學家們得以將大量且詳細的觀測資料儲存起來。由於收集到的天文資料其各個元素間是具有時間順序性的，而傳統的方法卻難以處理此類資料，所以我們選用字尾樹作為其結構的原型，提供天文學家快速而有效率的星體資料查詢功能，並且能夠在分析後提供與查詢相似的星體資訊給天文學家們。因為字尾樹的資料結構其記憶體使用量驚人，而天文資料的數量又十分龐大，在兩項因素交互影響之下，導致單一機器無法負荷，所以我們選用在開源的OpenStack系統上，建構Hadoop平台的雲端系統來構成分散式環境，將資料分散處理，以提升系統的整體效能。透過分散式系統處理大量的天文資料，減少了在資料處理上所耗費的人力，在效率上也得到了明顯的提升，提供了研究人員在未來面對大量觀測資料時一個有效的解決方法。在未來我們也期望能利用此系統架構來為所有具有時序性的資料作分析。"
    },
    {
        "resulNum": "78.",
        "title": "運用R語言與Hadoop分析開放資料-以天氣與農產品資料為例",
        "link": "https://hdl.handle.net/11296/7dd75x",
        "description": "近年來，由於開放資料（Open Data）被認定為涵有大量的潛在價值，故在資訊技術領域內已成為十分熱門的議題。而於開放資料中，政府開放資料（Open Government Data）已受西方各國與聯合國等國際組織的特別重視，並且大力推行。然而，於網際網路內釋出的開放資料，其資料格式過於繁雜，不同來源的資料常存在資料欄位定義的差異，導致資料整合與分析的不便。如何蒐集與整合其多元的開放資料並加以提供分析人員更迅速地進行資料分析與萃取重點資訊，成為當前熱門的話題。故本研究提出一項資料彙整分析平台雛型。其功能特色主要是可以自動進行開放資料的擷取與整併，結合Hadoop之巨量資料處理工具與R語言之資料探勘工具，以進行資料的分析處理，並於分析完成後自動留存關鍵因子，以提供後續決策分析使用。最後本研究則以農產品交易紀錄與歷史的天氣資料為例，經由本研究所開發之平台進行資料的擷取與整併，並透過平台內的決策樹之資料探勘方法進行迴圈式資料分析之行為，將每次分析模型儲存後，再依各農產品之類別來彙整其共同影響之因素，以提供決策者更完整的參考資訊。"
    },
    {
        "resulNum": "79.",
        "title": "運用CloudStack虛擬化環境整合物聯網架構與開放資料基於Hadoop雲端運算",
        "link": "https://hdl.handle.net/11296/2zjd4f",
        "description": "隨著資訊產業逐漸地發達，科技的進步使得網路時代的發達，讓人們對於智慧器材或是裝置更加的依賴，並且改變了人類的生活習慣。以行動設備結合感知識別，再透過感知識別的媒介來達到無所不在的聯網，資料的多樣性與重複性讓政府在近年來也開始推動開放資料(Open Data)，資料的傳輸與計算透過使用人數以及時間的遽增，勢必會衍生出巨量資料(Big Data)與在線使用承載率的問題產生，是值得探討與研究的問題。本論文提出一個混搭技術基於虛擬化雲端運算架構(Mashup Technology based on Virtualization Cloud Computing Framework，MTVCCF)，整合物聯網技術(Internet of Thing，IoT)、網路服務(Web Service，WS)與開放資料(Open Data，OD)作為前端系統架構的應用，並使用CloudStack以及Hadoop建構出虛擬化雲端運算架構之環境作為本系統後端的主要核心。透過Hadoop雲端運算來解決巨量資料運算的問題，使用CloudStack來建立、管理以及佈署雲端運算基本服務，搭配基於核心的虛擬機器(Kernel-based Virtual Machine，KVM)改善伺服器的可延展性以及解決使用率多寡的落差，降低伺服器當機的風險。本論文以老人照護為基礎發展出一個平台，此平台名稱為雲端老人照護平台(Elderly Care Cloud Platform，ECCP)，來驗證本論文所提出MTVCCF的可行性，ECCP的開發重點於量測生理訊號，搭配近距離無線通訊(Near Field Communication，NFC)、藍芽、電子式血壓計以及無線網路建構物聯網架構，讓物與物之間能互相溝通，而所產生的資料可透過Web Service將資料傳輸至後端進行運"
    },
    {
        "resulNum": "80.",
        "title": "企業導入雲端運算之影響-以Hadoop為例",
        "link": "https://hdl.handle.net/11296/c83ckt",
        "description": "目前雲端運算無疑是企業用來因應巨量資料需求的主要投資項目之一，而且在像 Facebook、Yahoo 這些大企業都宣稱自己在應用雲端運算來處理巨量資料分析上有相當良好的成效，這亦使得之後面臨巨量資料問題的企業起而效尤。大企業在傳統大型主機的運作上都遇到了速度、規模與成本的問題，所以，擁有處理巨量數據工具的分散式運算平台Hadoop即應運而生。本研究嘗試提出一個企業運用雲端運算能在降低成本的情況下，還可以在巨量資料下保有良好的效能及橫向擴充的彈性。本研究實驗測試企業常見之高階單一伺服器硬體與雲端運算中低階雲端技術架構，實驗結果顯示雲端運算架構對於巨量檔案的資料處理，較高階單一伺服器具有優秀的運作效能。"
    },
    {
        "resulNum": "81.",
        "title": "基於 Hadoop 叢集運算之個人化新聞追蹤及 推薦系統",
        "link": "https://hdl.handle.net/11296/czr4a3",
        "description": "由於網路新聞行業的發展及競爭，新聞以即時性及增加內容的多元性來吸引大眾的目光，如果使用者只閱讀一家新聞網站的訊息，容易造成對一個事件的認知錯誤而有不同觀點，同時也因為爆增的新聞中，夾雜或多或少可信度較低的文章，容易導致使用者吸收到錯誤資訊，須另花時間過濾及查證自己所關心的議題。本論文實作一個人化新聞追蹤及推薦系統，利用 Facebook 作為登入管道，擷取使用者及其好友的塗鴉牆內容，透過文字探勘（Text Mining）技術過濾無用的資訊，找出所有關鍵字並建立使用者輪廓；同時利用網路爬蟲（Web Crawler）至 PTT 及各新聞網站進行資料探勘（Data Mining），藉由改良 Jaccard 相似係數相似度計算分析所有新聞來源，找出相同事件並排列在一起進行事件追蹤。提供使用者不同立場的新聞訊息，有助於使用者更瞭解整個事件。透過社群資料及運用協同過濾技術來改善冷啟動、稀疏性等問題，除了能進行個人化推薦還能提供社交圈推薦，讓使用者能與社交圈朋友有更多共同話題。由於隨著時間不斷蒐集新聞而衍生大數據（Big Data）問題，傳統的關聯式資料庫將無法負荷，故本系統採用 Hadoop2叢集及 HBase 資料庫，利用 HBase 異地備份、分散式處理優點能有效率的存取巨量資料，加上高可用性集群（HA Cluster）故障轉移機制，盡量達到不中斷服務的原則。"
    },
    {
        "resulNum": "82.",
        "title": "應用派翠網路於Hadoop MapReduce 框架之建模與分析",
        "link": "https://hdl.handle.net/11296/z729wu",
        "description": "隨著科技的發展，公司企業的資料量日益龐大，進而發展出新的“雲端運算”、 “巨量資料” 概念，以及結合兩者使用的雲端運算作巨量資料分析的商機。Hadoop用在雲端運算系統的架設是非常熱門的，有許多雲端運算系統採用Hadoop作為實行之方法。其中，MapReduce框架為Hadoop進行巨量資料分析的核心，透過MapReduce的平行化架構可以大幅增加巨量資料分析的效率。本論文使用派翠網路針對MapReduce做視覺化建模，並驗證此模型滿足Reachability性質，再提出一個實際的巨量資料分析系統來驗證此模型的可行性，詳細描述了MapReduce平行化的內部細節，並指出在系統開發的過程中可能會犯下的錯誤，再以派翠網路模型提出錯誤預防機制，避免系統開發者與系統使用者犯錯，進而使系統開發能更有效率。"
    },
    {
        "resulNum": "83.",
        "title": "提升Hadoop MapReduce計算效能之研究-以抽取樣式歷史為例",
        "link": "https://hdl.handle.net/11296/3rg57u",
        "description": "Hadoop MapReduce是一種特殊的計算模式、具有處理巨量資料的能力。然而，在有限的計算資源環境條件下，如何調整其環境變數設定，以提升整體運算效能，屬於最佳化問題(Optimization Problem)。本論文以『利用Hadoop MapReduce 抽去最大樣式歷史資料』為例，採用貪婪方法(Greedy Method)來討論如何如何調整其環境變數設定，以提升Hadoop MapReduce效能，分為三個步驟：(1)計算節點個數(2)記憶體配置(3)Reduce數目，採用「最短計算時間」作為參數選擇標準，來討論樣式歷史抽取計算之最佳化問題。首先，先測試節點個數，然後依據Amazon Task Configuration與Hortonworks這兩家公司提供的記憶體配置方式，找出最好記憶體配置方式，最後根據此記憶體配置方式，去找出Reduce數目。實驗資料來源採用PubMed醫學文獻的論文標題與摘要，實驗結果表示，節點數目增加時，計算時間相對減少。當計算節點記憶體配置為Amazon Task Configuration參數值m1.medium時，計算時間最少；Reduce數目越多時，因為計算節點的數目固定，效能並不會相對明顯提升；本論文實驗結果可以提供給其他採用Hadoop-MapReduce計算模式的運算，在有限計算資源的條件下，如何提升效能之參考。"
    },
    {
        "resulNum": "84.",
        "title": "應用協同過濾之電影推薦服務於Hadoop平台",
        "link": "https://hdl.handle.net/11296/89pch7",
        "description": "資訊科技與網路的迅速發展改變了人們的生活習慣，範圍之廣甚至影響平時的購物行為。隨著網際網路的崛起，能夠對推薦系統做多方面的應用。在過去的研究上，主要針對內容導向式(Content-based)的推薦。經由個人過去的瀏覽模式、消費行為，預測其興趣與嗜好，使系統能夠在未來使用者消費前提供個人化的推薦。此方法存在推薦內容上的不完全，衍生出協同過濾(Collaborative filtering)推薦方式的應用。協同過濾方式主要透過喜好或經驗相同的群體推薦使用者感興趣的資訊。本論文建置個人化電影推薦系統，提供連結服務給外部應用程式，系統使用的推薦演算法以協同過濾為基礎。藉由連接豆瓣電影資料及Movielens使用者評分所提供的資料來源，儲存至NoSQL資料庫。電影評分數據提供給Mahout實作協同過濾推薦。外部程式可經由系統所提供的單一接口獲取這些數據。本論文雛型系統架設資料庫Cassandra，採用Hadoop來分析所收集的使用者資料，提高處理效率，運用Mahout來推薦使用者感興趣的電影，且具備取得使用者回饋的機制。論文最後，藉由使用者回饋資料實作三種相似演算法(Euclidean Distance、Maximum likelihood、Jaccard similarity coefficient)的準確率。再使用資訊檢索系統中常用的客觀指標，查全率(Recall Rate)與查準率(Precision Rate)進行比較。綜合考慮兩指標，使用F度量(F1-Measure)來評估本論文採用的演算法。"
    },
    {
        "resulNum": "85.",
        "title": "在Hadoop雲端系統基於ASIFT特徵之影像匹配",
        "link": "https://hdl.handle.net/11296/3ua3ek",
        "description": "在電腦視覺領域中，Scale Invariant Feature Transform (SIFT)是個很重要的演算法，因為他的特徵具備了尺度縮放、旋轉、亮度等不變性，而ASIFT是SIFT的延伸，他主要是解決了SIFT在傾斜方面無法處理的問題，雖然Affine SIFT (ASIFT)有著更多的特徵向量，但是也同時具有更龐大的計算複雜度。所以在這篇論文中，我們提出了在MapReduce的架構上使用ASIFT特徵的影像辨識系統，藉者用分散式的架構來提升速度。我們的系統使用ASIFT與Bag of Word以及Support Vector Machine (SVM)的組合，我們也在實驗中證明了此方法對不同類型的影像資料集比起其他方法具有更好的辨識度。"
    },
    {
        "resulNum": "86.",
        "title": "巨量資料於Hadoop平台基礎與架構之運用",
        "link": "https://hdl.handle.net/11296/4wt84m",
        "description": "隨著網際網路的普及和雲端技術的成熟，資料量持續遽增，現在常見的巨量資料例如社交網路上的打卡、相關的Log記錄、感測器的資訊、及網際網路上的檔案、影像及圖片、網路的搜尋引擎、天文的相關資料、大氣的科學分析、人類基因資料、生化醫療分析、醫學相關記錄。生活上大大小小的東西，幾乎都會產生資料，於是造就了專門來處理巨量資料的雲端平台。在雲端平台可以很方便快速地依照需求改變並且透過網路功能存取廣泛的共享運算資源（如網路資源、伺服器設備、儲存空間、應用程式、雲端服務等）。在雲端平台中的Hadoop架構，也因為開源軟體且功能彈性擴充的關係，更慢慢地被大家所熟知。在本論文中，我們基於Hadoop 平台概念，整合了HBase、Pig等相關元件，了解各個元件的概念與應用，進而建構出資料的分析架構，提供企業或有巨量資料需要分析之相關單位，藉以此平台達到快速資料處理與巨量資料分析之目的。"
    },
    {
        "resulNum": "87.",
        "title": "Hadoop 應用於 Cisco Netflow 路由封包 統計與異常流量分析之探討",
        "link": "https://hdl.handle.net/11296/462u28",
        "description": "本研究主要的目的是利用 Hadoop 作為平台，採用 MapReduce 演算方法，來統計分析巨量資料(Big Data)，分析其運算之效能、計算其時間與 Row Data統計之比較。研究以學校網路流量為統計分析的目標，透過收集路由器(Router)封包傳送紀錄，解析其來源與目的地 IP 位址，資料量大小與封包數量，並進行統計，計算出單一 IP 位址，當日流入與流出資料量加總數據，統計完成後排序當日前百名 IP 位址，作為異常流量追蹤分析的對象。一般巨量資料運用於 Rowdata 串列讀取後再進行計算，所耗費的時間較長，無法滿足要即時運算出結果之需求。如能將巨量資料先行 Map 後再進行 Reduce 之運作方式，則可加快運算結果而達到立即查詢之目的，且可有效改善網路流量統計運算方式，亦為本研究之目標。"
    },
    {
        "resulNum": "88.",
        "title": "基於OpenStack有效提升Hadoop擴充性與安全性的研究與發展",
        "link": "https://hdl.handle.net/11296/9avp73",
        "description": "雲端運算是近年來的一個新焦點、新方向，許多傳統的服務都慢慢開始雲端化，而雲端化的方式大多數都是透過虛擬化來達成，而虛擬化的工具、平台種類也很多，如:VMware的vSphere、Microsoft的Azure、Amazon的AWS以及開放原始碼的OpenStack等。本研究的目的是在將本實驗室以前所開發的BT-ECG[1][2]進行虛擬化，BT-ECG是一套基於Hadoop叢集的系統，我們把以前在實體機器上執行的Hadoop叢集移植到虛擬機器上執行，虛擬化Hadoop主機叢集後，可以快速的透過增加更多的節點，來達到性能的提升。本研究將使用開放原始碼的OpenStack打造一個一個私有雲。"
    },
    {
        "resulNum": "89.",
        "title": "基於 Hadoop 與 HBase 平台之 LCD Flicker 雲端儲存系統之實作",
        "link": "https://hdl.handle.net/11296/pg68y9",
        "description": "本論文，提出是一個LCD Flicker 雲端儲存系統，工廠可以上傳LCD Flicker測試結果到HBase資料庫， 然後即時產生反饋讓工程師來控制產線變異。LCD Flicker雲端儲存系統的目的是為了克服當前使用系統的缺點，它沒有能力來保存從生產線收集的數據。因為測量數據只儲存在測試設備中，無法回報給工程師，發生錯誤時，這個系統不可能用來分析和觀察變異的趨勢。因此，LCD Flicker雲端儲存系統具有線上即時監控量測數據的關鍵作用。此系統為私有雲(Private Could) 架構，主要使用於工廠與工廠之間的資料共享，並使用LCD Flicker 資料來做不良率分析。本文實驗使用虛擬化平台搭配Hadoop 與HBase，來做flicker 資料的傳送與訪問並分析系統效能，並藉此提升整體產品品質與效能。"
    },
    {
        "resulNum": "90.",
        "title": "Hadoop 雲端運算平台效能模式之評估與改善",
        "link": "https://hdl.handle.net/11296/6bvsk3",
        "description": "隨著網路普及以及行動技術的成熟，資料量的遽增，目前常見的巨量資料例如像社交網路的打卡、Log記錄、感測器資訊、網際網路上的檔案檔案、影音圖片、網路搜尋索引、天文資料、大氣科學分析、基因資料、生化分析、醫學記錄。生活上東西，幾乎都會產生資料所以就出現專門處理巨量資料的雲端平台。雲端平台能方便快速依照需求改變並透過網路功能存取廣泛的共享運算資源（如網路資源、伺服器設備、儲存空間、應用程式、雲端服務等）。雲端平台中的Hadoop平台因為開源軟體且彈性擴充的關係，也慢慢被大家所熟知。研究的Hadoop平台的效能的議題也開始被提出，像是任務排程、參數最佳化、檔案系統改善等問題。其中參數最佳化效能問題大部分都是透過模型來預測，並調整Hadoop層的參數來改善效能。此外開始有人把Hadoop與虛擬化的技術做結合。希望透過虛擬化的資源彈性的優勢，來提高Hadoop平台的效能。所以本研究希望建立一套跨IaaS、PaaS、SaaS層的跨層式參數優化模型(Cross-Layer Parameters Optimization Model, CPOM)的方法，並使用蟻群演算法串接三層IaaS、PaaS、SaaS層的優化方法，來提高Hadoop效能。在實驗的部分，透過Hadoop平台的實際運作來進行來驗證CPOM的可行性，並與Starfish做差異性比較。"
    },
    {
        "resulNum": "91.",
        "title": "利用時序特徵判讀心臟心律不整相關疾病特徵研究與Hadoop資料庫實作",
        "link": "https://hdl.handle.net/11296/uhc4gm",
        "description": "摘要本文目的在提出利用時序特徵的判讀方法,以便分類心臟的病徵現象,並借由平行運算的處理,將大量分類前後的資料儲存於資料庫端,以利未來醫療之運用。其所面臨的問題有以下，第一是取得出RR間隔，並以此時序的變化為輸入資料，透過時序辨識的方法，辨識正常節律、心律不整節律。分類器辨識波形包含正常節律、心律不整等。心電訊號資料是來自MIT-BIH Arrhythmia資料庫，選用5個檔案資料心跳週期，併使用台大林智仁老師的LIBSVM Function及演算法。時序特徵在雜訊的影響下正確率還是可接近100%，併計算特徵點到超平面的距離，與探討準確率的關係。"
    },
    {
        "resulNum": "92.",
        "title": "基於Hadoop叢集提升雲端運算之關聯式規則資料探勘技術",
        "link": "https://hdl.handle.net/11296/b6g4eb",
        "description": "關聯式資料探勘讓人們從不起眼的數據獲得有用的資訊。然而，現今數據的產量急速增加，對於探勘的演算法也需要有更好的資料處理能力。本論文針對PIETM (Principle of Inclusion-Exclusion and Transaction Mapping)關聯式資料探勘演算法提出完全平行化的方法來提升演算法運算能力，並且基於Hadoop MapReduce框架完成實作。PIETM演算法結合了Apriori與FP-growth兩演算法的優點，像是由下而上(Bottom-Up)的簡單搜尋方式以及整體探勘過程只需掃描兩次資料庫等優點。過去，有學者基於Hadoop MapReduce框架將PIETM平行化(簡稱BMR-PIETM)，不過仍有部分處理程序需要改進，例如：產生二階候選項目集、建立交易樹、降低交易區間表占用記憶體的空間。本研究以MapReduce框架及資料本身的結構特性提出了解決上述之問題的方法，特別是透過「間隔標籤(ITag)」將建立交易樹的過程平行化。另外也透過「間隔標籤(ITag)」將交易區間表的大小縮小。由於本研究完全的使用MapReduce框架將PIETM完全平行化，所以將此平行化之PIETM稱為Parallel-PIETM(簡稱P-PIETM)。本研究之解決方法，除了適用在Apriori演算法也適用在FP-growth演算法外，實驗結果顯示，P-PIETM演算法的效能可以比BMR-PIETM演算法以及Apriori演算法更好，效能提升最高可達66.17%。"
    },
    {
        "resulNum": "93.",
        "title": "Hadoop 結合R 之資料探勘 – 以TH 公司產品銷售預測為例",
        "link": "https://hdl.handle.net/11296/234g3a",
        "description": "近十幾年來，由於網際網路與雲端技術的高速發展而產生各種大量的數據。大數據(Big Data)似乎已是一個趨勢，在資料儲存、管理與處理各方面都發生了根本的轉變，企業如今需要儲存比以前更多的資料，且來源更廣、格式更加多元，並須了解如何將大數據轉變成有價值的資訊。顯然地，強而有力的軟體在資訊、數位與大數據的時代扮演著非常重要的角色。例如，軟體Apache的Hadoop，不僅有低成本高效益的優勢，而且具高靈活性、快處理速度、強容錯能力，與更好的擴展性，在大數據的存取與處理方面有極大的成效，加上R語言的RHadoop又可從多個資料源結合，更有助於對大數據的利用。資料探勘的目的就是從原始數據中萃取出高價值資訊，本研究以Hadoop與R語言結合進行資料探勘，目的是利用Hadoop的平行分散式處理技術與R語言的統計軟體演算，來探討大數據的儲存、處理、及檢索之功能。本研究使用TH企業提供的產品實際銷售量做為研究數據集，共28,764筆數據。利用RHadoop的倒傳遞類神經網路、C-SVC支援向量機與指數平滑法三種模型進行預測。研究發現，三者中以C-SVC支援向量機的預測最為準確。本研究結果可提供研究人員、管理者或企業決策人員，當他們面對大數據時，可行的決策指標或參考用。"
    },
    {
        "resulNum": "94.",
        "title": "基於Hadoop的基序與循序樣式探勘研究─以台灣家用電力時間序列資料為例",
        "link": "https://hdl.handle.net/11296/m66q8s",
        "description": "隨著環保意識的抬頭，節能減碳目標的追求，電力公司對於電力資料探勘需求日益增加，再加上智慧電表的逐漸普及，電力時間序列資料正在快速的成長，使得相關人員面臨了巨量資料分析與複雜運算之困難。而巨量資料中的目前最普及的解決方案就是使用開放式原始碼巨量資料處理平台Hadoop，透過其分散式編程架構MapReduce、分散式檔案系統HDFS 來處理巨量資料。在時間序列探勘中有個重要的研究議題就是基序(motif)探勘，基序是指在一個時間序列中重複出現的片段序列，藉由基序探勘，我們將能找出有意義的片段，並讓他代表一個事件，接著就能將一個時間序列轉換為一個事件序列並使用傳統的關聯法則找出用戶其隱藏的用電行為規則，而用電行為規則將對於節能減碳相關政策上的決定提供了相當大的參考價值。因此為了能解決傳統基序演算法對於巨量資料處理上的限制，本研究將基於Hadoop提出新的基序(motif)探勘演算法-「PrefixMotif」以及「MR_PrefixMotif」，PrefixMotif是由知名循序樣式探勘演算法PrefixSpan所改良。實驗結果顯示，在資料規模相當大的時候PrefixMotif比基序探勘研究中的常用方法Time Serise Project還要快上80倍以上且使用的記憶體空間更小，而做分散化處理後的「MR_PrefixMotif」在hadoop平台上執行，更隨著節點增加讓效能更是進一步的提昇，讓「MR_PrefixMotif」比起傳統的方法在執行效能上具有壓倒性的優勢。最後本研究也實作"
    },
    {
        "resulNum": "95.",
        "title": "利用Hadoop分佈式計算結構提升醫療大型資料處理速度—以健保資料庫為例",
        "link": "https://hdl.handle.net/11296/x23nn8",
        "description": "目前國內推進醫療雲端化，醫學資料開始有所改變，如電子病歷、遠距離醫療資料，使得不同類型的大量資料隨之而來。在醫學研究中，常常使用到一些不同資料的串檔，亦或是在產業合作間，也需要不同類型資料庫的整合。本研究目的在於使用常用資料庫工具MS SQL、MySQL時，執行分析查詢及串檔大量資料，面臨暫存空間不足與資料處理時間過長的問題。本研究利用健保資料庫上的大量資料，執行查詢語法在Hadoop和MS SQL、MySQL的效能比較上，證實Hadoop應用在醫療大型資料庫處理資料時間的效能為佳。最後利用Hadoop系統與Web結合成一健保資料庫雲端資料分析系統，並有助於增進Hadoop在醫學資料分析上的應用。"
    },
    {
        "resulNum": "96.",
        "title": "利用一Hadoop MapReduce鏈於建構機率尾置樹之研究",
        "link": "https://hdl.handle.net/11296/6564z6",
        "description": "序列資料(Sequence Data)是指具有順序關係的資料紀錄，序列資料在日常生活中是無處不在的，例如：蛋白質序列、股市交易、網頁瀏覽紀錄、移動軌跡、基因序列等。序列型樣探勘(Sequence Pattern Mining)是序列資料分析的技術之一，其主要目的是從序列資料中挖掘出隱藏其中的特殊、重要且具代表性的特徵(feature)，近來，此技術被廣泛的應用在生物資訊領域與時空軌跡資料的分析上，是資料探勘非常熱門的領域之一。機率尾置樹(Probabilistic Suffix Tree, PST) 是一種Variable-Length Markov Chain (VMM)的實作，它被廣泛的應用在序列型樣探勘(Sequence Pattern Mining)，一般認為，PST對序列資料的結構特徵或轉換行為，具有良好的擷取能力，非常適合用於預測和相似度比對。然而，隨著定位(Positioning)技術、感測(Sensing)技術的成熟，和無線(Wireless)技術演進，大量的序列資料被快速的累積，而傳統集中式的計算方法已經不堪負荷如此龐大資料(Big Data)的分析，因此，運算分散式運算雲端平台進行Big Data的計算是未來的趨勢。在本論文中，我們首先利用一個Na?ve方法來分析從Big Data建置機率尾置樹的困難點，為了解決Na?ve方法的缺陷，我們根據機率尾置樹的特性提出了一個新的CloudPST_OddEven MapReduce演算法，其包含一個MapReduce Chain，由四組MapReduce Tasks組成，分別負責型樣出現次數統計、尾置樹節點的組合、條件判斷等。為了驗證CloudPST_OddEven演算法的效率，我們建置雲端Hadoop平台，並設計資料產生器產生合成的序列資料，並進行一系列的實驗；實"
    },
    {
        "resulNum": "97.",
        "title": "基於Hadoop叢集之具關聯式規則探勘雲端系統設計與效能之研究",
        "link": "https://hdl.handle.net/11296/875n94",
        "description": "由於各類應用的資料規模或特性已經超過傳統資料庫系統的處理能力，因此需要新的有效率的資料處理技術來巨量處理。因此，必須有巨量資料的儲存空間。另一方面，也必須思考如何處理或運用這些儲存下來的巨量資料。而巨量資料(Big data)通常是指大容量(high-volume)、即時性(high-velocity)及多元化(high-variety)的資訊，必須透過有效率的處理程序，來促進資料的分析及應用。而對於巨量資料來說，資料探勘是一個重要的問題，尤其是雲端應用服務在巨量資料上的資料分類、關聯分析和預測技術上的開發，在未來將是一個提升有效的應用服務的關鍵。本研究提出設計於開放式原始碼Hadoop框架平台上建構一以MapReduce雲端巨量處理架構並整合HDFS、HBase與MapReduce等開放原始碼的子架構，實作平行化關聯式規則演算法與循序樣式分析演算法，其目的在於提升關聯規則與循序樣本資料探勘處理巨量資料之效能系統設計。並以Hadoop叢集實測其效能，其中影響關聯式規則演算法與循序樣本分析演算法效能的因素有實驗環境、演算法特性、叢集節點數目、輸入資料特性、資料總量、Map Tasks總數以及Reduce Tasks總數等參數，本研究將以兩種實驗資料集，透過各種參數之組合進行系統效能測試，並分析這些資料結果，評估與設計一個最適合旅遊網使用者連線紀錄特性的關聯式規則與循序樣式分析演算法與實驗環境跟參數設定"
    },
    {
        "resulNum": "98.",
        "title": "使用Hadoop搭配PHP連結管理HBase",
        "link": "https://hdl.handle.net/11296/79uzcr",
        "description": "在日新月異的時代裡，資訊的流通速度逐年增加，同樣地資料處理的速度相對需要增進許多，而雲端處理技術也因此發展了出來。雲端運算透過網際網路來把巨量的資料透過運算程序，分成數個小型運算分給叢集內的電腦作運算，再交由數台分配任務的伺服器叢集而成的系統，透過分析與運算，將所得的結果回傳給使用者。在Hadoop來說，會把需要的資料分為數個子項目(Mapper) ，處理完畢後，再做資料的結合(Reduce)，而此一作法我們通稱為『分散式運算』。然而Hadoop搭配上HBase，可藉由儲存在資料庫的資料來做分散式運算，也較方便歸類整理與處理大量的資料。但是，在HBase的操作上卻是大大的不便捷，本論文搭配PHP網頁的方式，以及使用Thrift套件作為溝通的橋樑，來去直接存取HBase的基礎功能(如資料表的查詢、新增、更新、關閉、刪除等)，在操作上定能大大的提升方便性與讓使用者快速上手。"
    },
    {
        "resulNum": "99.",
        "title": "使用服務導向架構整合語意網技術於Hadoop與HBase",
        "link": "https://hdl.handle.net/11296/637s4t",
        "description": "近年來網際網路的主流趨勢是社群網站，在人們普遍使用之下，資料成長是相當可觀的，社群網站的資料勢必構成巨量資料(Big Data)，這將導致系統在搜尋、儲存與運算效能上的嚴重負荷。本研究提出一個具語意服務導向的雲端運算架構(Semantic Service-Oriented Cloud Computing Framework，SSOCCF)，整合服務導向架構(Service-Oriented Architecture，SOA)與語意網(Semantic Web)技術於Hadoop雲端運算的環境，透過Hadoop雲端運算來改善社群網站中巨量資料的運算效能，採用語意網技術來改善巨量資料的搜尋效能，並使用HBase分散式資料庫來解決巨量資料的存取效能，HBase能有效分散式儲存和管理，並且支援Hadoop的MapReduce分散式運算，強化系統運算能力。本研究發展以餐飲為例的社群平台命名為餐飲社群平台(Diet Social Platform，DSP)，來驗證本研究所提出SSOCCF的可行性，在DSP中，針於餐飲資訊的分享以行動設備掃描QR Code作為識別依據，透過SOA啟動遠端的雲端運算，這也可提供其它平台來呼叫使用，提高重複使用與可擴充性。此外，DSP搜尋是基於語意網技術，由知識本體(Ontology)分類相關資訊，並制定Rule關係判斷，透過推論引擎區分資訊相關性，藉此尋找到符合使用者的資訊。經實際DSP的巨量資料測試，本研究所提出的SSOCCF能改善前述社群網站中巨量資料所衍生的問題。"
    },
    {
        "resulNum": "100.",
        "title": "以Hadoop平台為框架加速電子病歷交換之系統設計",
        "link": "https://hdl.handle.net/11296/7gmmue",
        "description": "如今隨著雲端運算技術的日益發展，使得資料的儲存與使用方式得以無遠弗屆，從而衍生出巨量資料的相關議題。而台灣衛生福利部為了促進民眾健康水準與提升醫療資源的使用率，近年來不斷地積極推動各地醫療院所實施電子病歷交換，並成立電子病歷交換中心來協助查詢各醫院的病歷索引。然而目前實施交換的電子病歷只有基本的四大單張報告(出院病摘、門診用藥、血液檢驗、醫學影像)，要達到真正的電子病歷交換還有很長的一段距離。並且醫學資訊涵蓋廣泛，要如何統整與管理不同醫院之間的資料，勢必會是一項相當大的挑戰。是故本研究使用現今主流的巨量資料分析工具Hadoop，結合HBase實作出一套適合巨量電子病歷資料的交換系統，用以解決龐大且複雜的病歷資料。當中為了加速電子病歷的儲存與查詢，系統中利用MapReduce的分散式處理機制，來加速電子病歷資料的處理。此外為了讓電子病歷能快速的儲存於HBase中，本研究根據病歷交換資料的特性設計出相關rowkey與表格架構，藉此提升HBase的儲存效率。在實驗環境中，我們依據所設計的HBase表格架構，探討在不同的rowkey與column family之下，對於HBase效能的影響。實驗結果顯示，本研究所設計的HBase表格架構在處理巨量電子病歷的資料上，具有良好的處理效率。最終期望透過本研究的發現，能夠讓台灣衛生福利部考量將電子病歷導入巨"
    }
]